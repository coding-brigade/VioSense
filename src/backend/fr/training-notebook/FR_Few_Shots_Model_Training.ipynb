{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TRAUZFEgj5Y1",
        "1qvmsZWqhQPy",
        "k0sLKdCeqZZJ"
      ],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGvngMpNZ1xu",
        "outputId": "ffa15985-5223-49e1-90c0-61483629d7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Coding Brigades Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "BNLNLLyfidrb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This Colab File is used for Training Few-shot models\n",
        "\n",
        "## Contents\n",
        "---\n",
        "- [LBP (R=1)](#lbp-r-1)\n",
        "  - [KSV Dataset](#lbp-r-1-ksv-dataset)\n",
        "    - [KSV Dataset - SVC](#lbp-r-1-ksv-dataset-svc)\n",
        "        - [KSV Dataset - SVC : Linear Kernel](#lbp-r-1-ksv-dataset-svc-linear-kernel)\n",
        "        - [KSV Dataset - SVC : RBF Kernel](#lbp-r-1-ksv-dataset-svc-rbf-kernel)\n",
        "        - [KSV Dataset - SVC : Sigmoid](#lbp-r-1-ksv-dataset-svc-sigmoid)\n",
        "    - [KSV Dataset - KNN](#lbp-r-1-ksv-dataset-knn)\n",
        "        - [KSV Dataset - KNN : Penalty=\"none\"](#lbp-r-1-ksv-dataset-knn-penalty-none)\n",
        "        - [KSV Dataset - KNN : Penalty=\"l2\"](#lbp-r-1-ksv-dataset-knn-penalty-l2)\n",
        "    - [KSV Dataset - KNN + CNN](#lbp-r-1-ksv-dataset-knn-cnn)\n",
        "  - [Yale Dataset](#lbp-r-1-yale-dataset)\n",
        "    - [Yale Dataset - SVC](#lbp-r-1-yale-dataset-svc)\n",
        "        - [Yale Dataset - SVC : Linear Kernel](#lbp-r-1-yale-dataset-svc-linear-kernel)\n",
        "        - [Yale Dataset - SVC : RBF Kernel](#lbp-r-1-yale-dataset-svc-rbf-kernel)\n",
        "        - [Yale Dataset - SVC : Sigmoid](#lbp-r-1-yale-dataset-svc-sigmoid)\n",
        "    - [Yale Dataset - KNN](#lbp-r-1-yale-dataset-knn)\n",
        "        - [Yale Dataset - KNN : Penalty=\"none\"](#lbp-r-1-yale-dataset-knn-penalty-none)\n",
        "        - [Yale Dataset - KNN : Penalty=\"l2\"](#lbp-r-1-yale-dataset-knn-penalty-l2)\n",
        "    - [Yale Dataset - KNN + CNN](#lbp-r-1-yale-dataset-knn-cnn)\n",
        "  - [ORL Dataset](#lbp-r-1-orl-dataset)\n",
        "    - [ORL Dataset - SVC](#lbp-r-1-orl-dataset-svc)\n",
        "        - [ORL Dataset - SVC : Linear Kernel](#lbp-r-1-orl-dataset-svc-linear-kernel)\n",
        "        - [ORL Dataset - SVC : RBF Kernel](#lbp-r-1-orl-dataset-svc-rbf-kernel)\n",
        "        - [ORL Dataset - SVC : Sigmoid](#lbp-r-1-orl-dataset-svc-sigmoid)\n",
        "    - [ORL Dataset - KNN](#lbp-r-1-orl-dataset-knn)\n",
        "        - [ORL Dataset - KNN : Penalty=\"none\"](#lbp-r-1-orl-dataset-knn-penalty-none)\n",
        "        - [ORL Dataset - KNN : Penalty=\"l2\"](#lbp-r-1-orl-dataset-knn-penalty-l2)\n",
        "    - [ORL Dataset - KNN + CNN](#lbp-r-1-orl-dataset-knn-cnn)\n",
        "  - [LFW Dataset](#lbp-r-1-lfw-dataset)\n",
        "    - [LFW Dataset - SVC](#lbp-r-1-lfw-dataset-svc)\n",
        "        - [LFW Dataset - SVC : Linear Kernel](#lbp-r-1-lfw-dataset-svc-linear-kernel)\n",
        "        - [LFW Dataset - SVC : RBF Kernel](#lbp-r-1-lfw-dataset-svc-rbf-kernel)\n",
        "        - [LFW Dataset - SVC : Sigmoid](#lbp-r-1-lfw-dataset-svc-sigmoid)\n",
        "    - [LFW Dataset - KNN](#lbp-r-1-lfw-dataset-knn)\n",
        "        - [LFW Dataset - KNN : Penalty=\"none\"](#lbp-r-1-lfw-dataset-knn-penalty-none)\n",
        "        - [LFW Dataset - KNN : Penalty=\"l2\"](#lbp-r-1-lfw-dataset-knn-penalty-l2)\n",
        "    - [LFW Dataset - KNN + CNN](#lbp-r-1-lfw-dataset-knn-cnn)\n",
        "---\n",
        "- [LBP (R=2)](#lbp-r-2)\n",
        "  - [KSV Dataset](#lbp-r-2-ksv-dataset)\n",
        "    - [KSV Dataset - SVC](#lbp-r-2-ksv-dataset-svc)\n",
        "        - [KSV Dataset - SVC : Linear Kernel](#lbp-r-2-ksv-dataset-svc-linear-kernel)\n",
        "        - [KSV Dataset - SVC : RBF Kernel](#lbp-r-2-ksv-dataset-svc-rbf-kernel)\n",
        "        - [KSV Dataset - SVC : Sigmoid](#lbp-r-2-ksv-dataset-svc-sigmoid)\n",
        "    - [KSV Dataset - KNN](#lbp-r-2-ksv-dataset-knn)\n",
        "        - [KSV Dataset - KNN : Penalty=\"none\"](#lbp-r-2-ksv-dataset-knn-penalty-none)\n",
        "        - [KSV Dataset - KNN : Penalty=\"l2\"](#lbp-r-2-ksv-dataset-knn-penalty-l2)\n",
        "    - [KSV Dataset - KNN + CNN](#lbp-r-2-ksv-dataset-knn-cnn)\n",
        "  - [Yale Dataset](#lbp-r-2-yale-dataset)\n",
        "    - [Yale Dataset - SVC](#lbp-r-2-yale-dataset-svc)\n",
        "        - [Yale Dataset - SVC : Linear Kernel](#lbp-r-2-yale-dataset-svc-linear-kernel)\n",
        "        - [Yale Dataset - SVC : RBF Kernel](#lbp-r-2-yale-dataset-svc-rbf-kernel)\n",
        "        - [Yale Dataset - SVC : Sigmoid](#lbp-r-2-yale-dataset-svc-sigmoid)\n",
        "    - [Yale Dataset - KNN](#lbp-r-2-yale-dataset-knn)\n",
        "        - [Yale Dataset - KNN : Penalty=\"none\"](#lbp-r-2-yale-dataset-knn-penalty-none)\n",
        "        - [Yale Dataset - KNN : Penalty=\"l2\"](#lbp-r-2-yale-dataset-knn-penalty-l2)\n",
        "    - [Yale Dataset - KNN + CNN](#lbp-r-2-yale-dataset-knn-cnn)\n",
        "  - [ORL Dataset](#lbp-r-2-orl-dataset)\n",
        "    - [ORL Dataset - SVC](#lbp-r-2-orl-dataset-svc)\n",
        "        - [ORL Dataset - SVC : Linear Kernel](#lbp-r-2-orl-dataset-svc-linear-kernel)\n",
        "        - [ORL Dataset - SVC : RBF Kernel](#lbp-r-2-orl-dataset-svc-rbf-kernel)\n",
        "        - [ORL Dataset - SVC : Sigmoid](#lbp-r-2-orl-dataset-svc-sigmoid)\n",
        "    - [ORL Dataset - KNN](#lbp-r-2-orl-dataset-knn)\n",
        "        - [ORL Dataset - KNN : Penalty=\"none\"](#lbp-r-2-orl-dataset-knn-penalty-none)\n",
        "        - [ORL Dataset - KNN : Penalty=\"l2\"](#lbp-r-2-orl-dataset-knn-penalty-l2)\n",
        "    - [ORL Dataset - KNN + CNN](#lbp-r-2-orl-dataset-knn-cnn)\n",
        "  - [LFW Dataset](#lbp-r-2-lfw-dataset)\n",
        "    - [LFW Dataset - SVC](#lbp-r-2-lfw-dataset-svc)\n",
        "        - [LFW Dataset - SVC : Linear Kernel](#lbp-r-2-lfw-dataset-svc-linear-kernel)\n",
        "        - [LFW Dataset - SVC : RBF Kernel](#lbp-r-2-lfw-dataset-svc-rbf-kernel)\n",
        "        - [LFW Dataset - SVC : Sigmoid](#lbp-r-2-lfw-dataset-svc-sigmoid)\n",
        "    - [LFW Dataset - KNN](#lbp-r-2-lfw-dataset-knn)\n",
        "        - [LFW Dataset - KNN : Penalty=\"none\"](#lbp-r-2-lfw-dataset-knn-penalty-none)\n",
        "        - [LFW Dataset - KNN : Penalty=\"l2\"](#lbp-r-2-lfw-dataset-knn-penalty-l2)\n",
        "    - [LFW Dataset - KNN + CNN](#lbp-r-2-lfw-dataset-knn-cnn)\n",
        "---\n",
        "- [LBP (R=3)](#lbp-r-3)\n",
        "  - [KSV Dataset](#lbp-r-3-ksv-dataset)\n",
        "    - [KSV Dataset - SVC](#lbp-r-3-ksv-dataset-svc)\n",
        "        - [KSV Dataset - SVC : Linear Kernel](#lbp-r-3-ksv-dataset-svc-linear-kernel)\n",
        "        - [KSV Dataset - SVC : RBF Kernel](#lbp-r-3-ksv-dataset-svc-rbf-kernel)\n",
        "        - [KSV Dataset - SVC : Sigmoid](#lbp-r-3-ksv-dataset-svc-sigmoid)\n",
        "    - [KSV Dataset - KNN](#lbp-r-3-ksv-dataset-knn)\n",
        "        - [KSV Dataset - KNN : Penalty=\"none\"](#lbp-r-3-ksv-dataset-knn-penalty-none)\n",
        "        - [KSV Dataset - KNN : Penalty=\"l2\"](#lbp-r-3-ksv-dataset-knn-penalty-l2)\n",
        "    - [KSV Dataset - KNN + CNN](#lbp-r-3-ksv-dataset-knn-cnn)\n",
        "  - [Yale Dataset](#lbp-r-3-yale-dataset)\n",
        "    - [Yale Dataset - SVC](#lbp-r-3-yale-dataset-svc)\n",
        "        - [Yale Dataset - SVC : Linear Kernel](#lbp-r-3-yale-dataset-svc-linear-kernel)\n",
        "        - [Yale Dataset - SVC : RBF Kernel](#lbp-r-3-yale-dataset-svc-rbf-kernel)\n",
        "        - [Yale Dataset - SVC : Sigmoid](#lbp-r-3-yale-dataset-svc-sigmoid)\n",
        "    - [Yale Dataset - KNN](#lbp-r-3-yale-dataset-knn)\n",
        "        - [Yale Dataset - KNN : Penalty=\"none\"](#lbp-r-3-yale-dataset-knn-penalty-none)\n",
        "        - [Yale Dataset - KNN : Penalty=\"l2\"](#lbp-r-3-yale-dataset-knn-penalty-l2)\n",
        "    - [Yale Dataset - KNN + CNN](#lbp-r-3-yale-dataset-knn-cnn)\n",
        "  - [ORL Dataset](#lbp-r-3-orl-dataset)\n",
        "    - [ORL Dataset - SVC](#lbp-r-3-orl-dataset-svc)\n",
        "        - [ORL Dataset - SVC : Linear Kernel](#lbp-r-3-orl-dataset-svc-linear-kernel)\n",
        "        - [ORL Dataset - SVC : RBF Kernel](#lbp-r-3-orl-dataset-svc-rbf-kernel)\n",
        "        - [ORL Dataset - SVC : Sigmoid](#lbp-r-3-orl-dataset-svc-sigmoid)\n",
        "    - [ORL Dataset - KNN](#lbp-r-3-orl-dataset-knn)\n",
        "        - [ORL Dataset - KNN : Penalty=\"none\"](#lbp-r-3-orl-dataset-knn-penalty-none)\n",
        "        - [ORL Dataset - KNN : Penalty=\"l2\"](#lbp-r-3-orl-dataset-knn-penalty-l2)\n",
        "    - [ORL Dataset - KNN + CNN](#lbp-r-3-orl-dataset-knn-cnn)\n",
        "  - [LFW Dataset](#lbp-r-3-lfw-dataset)\n",
        "    - [LFW Dataset - SVC](#lbp-r-3-lfw-dataset-svc)\n",
        "        - [LFW Dataset - SVC : Linear Kernel](#lbp-r-3-lfw-dataset-svc-linear-kernel)\n",
        "        - [LFW Dataset - SVC : RBF Kernel](#lbp-r-3-lfw-dataset-svc-rbf-kernel)\n",
        "        - [LFW Dataset - SVC : Sigmoid](#lbp-r-3-lfw-dataset-svc-sigmoid)\n",
        "    - [LFW Dataset - KNN](#lbp-r-3-lfw-dataset-knn)\n",
        "        - [LFW Dataset - KNN : Penalty=\"none\"](#lbp-r-3-lfw-dataset-knn-penalty-none)\n",
        "        - [LFW Dataset - KNN : Penalty=\"l2\"](#lbp-r-3-lfw-dataset-knn-penalty-l2)\n",
        "    - [LFW Dataset - KNN + CNN](#lbp-r-3-lfw-dataset-knn-cnn)\n"
      ],
      "metadata": {
        "id": "wWsfmw5YZ_-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LBP Function"
      ],
      "metadata": {
        "id": "TRAUZFEgj5Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LBP Function Remains common for LBP R= 1,2 and 3\n",
        "def LBP(image, P, R):   # Convert the single image into LBP\n",
        "\n",
        "    # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = image\n",
        "    # Create an empty matrix to store the LBP image\n",
        "    lbp_image = np.zeros_like(gray)\n",
        "    # print(f'gray shape : - {gray.shape}')\n",
        "    # Loop over each pixel in the image\n",
        "    for i in range(R, gray.shape[0] - R):   #  (R=1, 10 - 1 = 9), (R=2, 10 - 2 = 8) i= central pixel\n",
        "        for j in range(R, gray.shape[1] - R):\n",
        "            # Extract the P neighborhoods that surround the central pixel\n",
        "            neighbors = []\n",
        "            for p in range(P):\n",
        "                x = int(i + R * np.sin(2 * np.pi * p / P))\n",
        "                y = int(j + R * np.cos(2 * np.pi * p / P))\n",
        "                neighbors.append(gray[x, y])\n",
        "            # Take the center pixel and set it as a threshold for its P neighbors\n",
        "            center = gray[i, j]\n",
        "            binary = [int(n >= center) for n in neighbors]\n",
        "            # Convert the binary code into decimal\n",
        "            lbp_code = sum([binary[p] * 2 ** p for p in range(P)])\n",
        "            # Replace the center pixel value with resulted decimal\n",
        "            lbp_image[i, j] = lbp_code\n",
        "    return lbp_image"
      ],
      "metadata": {
        "id": "wX1relfGinj2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1'></a>\n",
        "# LBP (R=1)"
      ],
      "metadata": {
        "id": "1qvmsZWqhQPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skimage import feature\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def get_lbp_features(image, radius=1, n_points=8):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate LBP features\n",
        "    # lbp = feature.local_binary_pattern(gray, n_points, radius, method=\"uniform\")\n",
        "    lbp = LBP(gray,n_points,radius)\n",
        "\n",
        "    # Calculate a histogram of the LBP features\n",
        "    grid_x = 16\n",
        "    grid_y = 16\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    height, width, channel = image.shape\n",
        "\n",
        "    # Calculate the size of each grid\n",
        "    grid_height = height // grid_y\n",
        "    grid_width = width // grid_x\n",
        "\n",
        "    # Initialize an empty list to store the histograms\n",
        "    histograms = []\n",
        "\n",
        "    # Loop through the grids\n",
        "    for i in range(grid_y):\n",
        "        for j in range(grid_x):\n",
        "            # Get the sub-image of the current grid\n",
        "            sub_img = lbp[i * grid_height:(i + 1) * grid_height, j * grid_width:(j + 1) * grid_width]\n",
        "\n",
        "            # Compute the histogram of the sub-image\n",
        "            hist, bins = np.histogram(sub_img, bins=256, range=(0, 255))\n",
        "            histograms.append(hist)\n",
        "\n",
        "    # Concatenate the histograms into a single array\n",
        "    final_histogram = np.concatenate(histograms)\n",
        "\n",
        "    hist = np.array(final_histogram)\n",
        "    # Normalize the histogram\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "-AfA0WtwiYmv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset'></a>\n",
        "## LBP (R=1) on KSV Dataset"
      ],
      "metadata": {
        "id": "A-Uxof6ohdXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for image_file in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/KSV_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "8ODC9MP1i5Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-svc'></a>\n",
        "### R=1 - KSV dataset : SVC"
      ],
      "metadata": {
        "id": "yXjeEiBEhuNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "lzsUGUmjiDd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DOAhAUmaOcn",
        "outputId": "6438f2ae-17cc-45cb-94d4-0f14633dd4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5758\n",
            "F1 Score: 0.5932\n",
            "Precision: 0.7091\n",
            "Recall: 0.5758\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.40      0.57         5\n",
            "  21BEIT30044       1.00      0.75      0.86         4\n",
            "  21BEIT30048       0.20      0.50      0.29         2\n",
            "  21BEIT30053       0.33      0.50      0.40         2\n",
            "  21BEIT30090       0.67      0.67      0.67         3\n",
            "  21BEIT30092       0.33      0.50      0.40         2\n",
            "  21BEIT30100       0.50      0.50      0.50         2\n",
            "  21BEIT30105       0.75      0.75      0.75         4\n",
            "  21BEIT30128       0.67      0.50      0.57         4\n",
            "  21BEIT30135       0.50      1.00      0.67         2\n",
            "222SBEIT30014       1.00      0.33      0.50         3\n",
            "\n",
            "     accuracy                           0.58        33\n",
            "    macro avg       0.63      0.58      0.56        33\n",
            " weighted avg       0.71      0.58      0.59        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "ws10epOmjBWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnYhniOpjFYp",
        "outputId": "ea5d7614-2336-46b3-d5b0-03fa50e77805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5152\n",
            "F1 Score: 0.4786\n",
            "Precision: 0.5062\n",
            "Recall: 0.5152\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         5\n",
            "  21BEIT30044       1.00      0.75      0.86         4\n",
            "  21BEIT30048       0.20      0.50      0.29         2\n",
            "  21BEIT30053       0.20      0.50      0.29         2\n",
            "  21BEIT30090       1.00      0.67      0.80         3\n",
            "  21BEIT30092       0.29      1.00      0.44         2\n",
            "  21BEIT30100       0.67      1.00      0.80         2\n",
            "  21BEIT30105       0.75      0.75      0.75         4\n",
            "  21BEIT30128       0.50      0.25      0.33         4\n",
            "  21BEIT30135       1.00      1.00      1.00         2\n",
            "222SBEIT30014       0.00      0.00      0.00         3\n",
            "\n",
            "     accuracy                           0.52        33\n",
            "    macro avg       0.51      0.58      0.51        33\n",
            " weighted avg       0.51      0.52      0.48        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "Bsq8FYDGjI3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s89Qt_GejO8s",
        "outputId": "78f3ded9-a723-4097-c5d0-c6b9caef9465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6364\n",
            "F1 Score: 0.6436\n",
            "Precision: 0.7222\n",
            "Recall: 0.6364\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.40      0.57         5\n",
            "  21BEIT30044       1.00      0.75      0.86         4\n",
            "  21BEIT30048       0.33      0.50      0.40         2\n",
            "  21BEIT30053       0.50      0.50      0.50         2\n",
            "  21BEIT30090       1.00      0.67      0.80         3\n",
            "  21BEIT30092       0.25      0.50      0.33         2\n",
            "  21BEIT30100       0.67      1.00      0.80         2\n",
            "  21BEIT30105       0.67      1.00      0.80         4\n",
            "  21BEIT30128       0.67      0.50      0.57         4\n",
            "  21BEIT30135       1.00      1.00      1.00         2\n",
            "222SBEIT30014       0.33      0.33      0.33         3\n",
            "\n",
            "     accuracy                           0.64        33\n",
            "    macro avg       0.67      0.65      0.63        33\n",
            " weighted avg       0.72      0.64      0.64        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-knn'></a>\n",
        "### R=1 - KSV dataset : KNN"
      ],
      "metadata": {
        "id": "rCH0jwqUjRqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeWZeFBpjih9",
        "outputId": "9938a17d-55ad-4e09-a368-d9223dec7980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3030\n",
            "F1 Score: 0.2414\n",
            "Precision: 0.2859\n",
            "Recall: 0.3030\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         3\n",
            "  21BEIT30044       0.67      1.00      0.80         2\n",
            "  21BEIT30048       0.20      1.00      0.33         3\n",
            "  21BEIT30053       0.50      0.33      0.40         3\n",
            "  21BEIT30090       0.00      0.00      0.00         3\n",
            "  21BEIT30092       0.00      0.00      0.00         2\n",
            "  21BEIT30100       0.00      0.00      0.00         3\n",
            "  21BEIT30105       0.50      1.00      0.67         2\n",
            "  21BEIT30128       0.50      0.17      0.25         6\n",
            "  21BEIT30135       0.50      0.25      0.33         4\n",
            "222SBEIT30014       0.00      0.00      0.00         2\n",
            "\n",
            "     accuracy                           0.30        33\n",
            "    macro avg       0.26      0.34      0.25        33\n",
            " weighted avg       0.29      0.30      0.24        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "VwKOmSO3jZCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYNuynEyjW1F",
        "outputId": "f68c42db-a001-4b64-ef1c-01840e80f5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4545\n",
            "F1 Score: 0.4401\n",
            "Precision: 0.5086\n",
            "Recall: 0.4545\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 0 0 0 0 0 0 0 0 0 1]\n",
            " [1 5 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 1 0 0 0 0 1]\n",
            " [0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 4 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1 1 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.40      0.67      0.50         3\n",
            "  21BEIT30044       0.62      0.83      0.71         6\n",
            "  21BEIT30048       1.00      0.50      0.67         4\n",
            "  21BEIT30053       1.00      0.33      0.50         3\n",
            "  21BEIT30090       1.00      1.00      1.00         2\n",
            "  21BEIT30092       0.00      0.00      0.00         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.00      0.00      0.00         2\n",
            "  21BEIT30128       0.17      1.00      0.29         1\n",
            "  21BEIT30135       0.67      0.50      0.57         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.45        33\n",
            "    macro avg       0.44      0.44      0.39        33\n",
            " weighted avg       0.51      0.45      0.44        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-ksv-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "kf9NTLTUjx3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vVHgcJjjoUS",
        "outputId": "62c5cb74-de97-4d4f-ad82-439a04eb1ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42\n",
            "F1 Score: 0.40\n",
            "Precision: 0.44\n",
            "Recall: 0.42\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 1 1 0 0 0 0 0 0 0 0]\n",
            " [0 5 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 2 0 0 1 0 0 0 1 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 1 0 0 1 2 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.33      0.33      0.33         3\n",
            "  21BEIT30044       0.56      0.83      0.67         6\n",
            "  21BEIT30048       0.67      0.50      0.57         4\n",
            "  21BEIT30053       1.00      0.33      0.50         3\n",
            "  21BEIT30090       0.67      1.00      0.80         2\n",
            "  21BEIT30092       0.33      0.17      0.22         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.25      0.50      0.33         2\n",
            "  21BEIT30128       0.00      0.00      0.00         1\n",
            "  21BEIT30135       0.20      0.25      0.22         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.42        33\n",
            "    macro avg       0.36      0.36      0.33        33\n",
            " weighted avg       0.44      0.42      0.40        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset'></a>\n",
        "## LBP (R=1) on Yale Dataset"
      ],
      "metadata": {
        "id": "nZNVkR0zrUTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for gif_file in os.listdir(class_path):\n",
        "            gif_path = os.path.join(class_path, gif_file)\n",
        "\n",
        "            gif_image = Image.open(gif_path)\n",
        "            rgb_image = gif_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/Yale_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "4RoqDM0ZrUTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-svc'></a>\n",
        "### R=1 - Yale dataset : SVC"
      ],
      "metadata": {
        "id": "3O9TxFD7rUTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "yjHO3HfvrUTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4102fc-49eb-40f9-9b1f-8651e7783bf9",
        "id": "l_apctPkrUTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7879\n",
            "F1 Score: 0.7934\n",
            "Precision: 0.9081\n",
            "Recall: 0.7879\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.50      1.00      0.67         1\n",
            "   subject04       0.83      1.00      0.91         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       0.50      1.00      0.67         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       1.00      1.00      1.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.79        33\n",
            "   macro avg       0.82      0.79      0.76        33\n",
            "weighted avg       0.91      0.79      0.79        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "lnySOtZ4rUTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938c60e9-3e11-4ea7-c1b1-466fe363b015",
        "id": "btTZwaUtrUTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7273\n",
            "F1 Score: 0.7504\n",
            "Precision: 0.8949\n",
            "Recall: 0.7273\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       1.00      1.00      1.00         1\n",
            "   subject04       1.00      1.00      1.00         5\n",
            "   subject05       1.00      0.50      0.67         2\n",
            "   subject06       0.20      1.00      0.33         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       0.67      1.00      0.80         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.73        33\n",
            "   macro avg       0.76      0.69      0.67        33\n",
            "weighted avg       0.89      0.73      0.75        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "LkXxqCwdrUTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39647825-a429-47e5-a3db-1d3b413c0cbe",
        "id": "rWCuuagcrUTr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7576\n",
            "F1 Score: 0.7639\n",
            "Precision: 0.8838\n",
            "Recall: 0.7576\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.33      1.00      0.50         1\n",
            "   subject04       0.83      1.00      0.91         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       1.00      1.00      1.00         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.33      1.00      0.50         2\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.77      0.72      0.70        33\n",
            "weighted avg       0.88      0.76      0.76        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-knn'></a>\n",
        "### R=1 - Yale dataset : KNN"
      ],
      "metadata": {
        "id": "5Q1dbLYarUTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0edafc8-a22c-4c44-8642-6aab9283f629",
        "id": "ShPL_22WrUTs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7576\n",
            "F1 Score: 0.7584\n",
            "Precision: 0.8273\n",
            "Recall: 0.7576\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       0.50      0.50      0.50         2\n",
            "   subject02       0.00      0.00      0.00         1\n",
            "   subject03       1.00      0.50      0.67         2\n",
            "   subject04       1.00      0.50      0.67         4\n",
            "   subject05       0.60      1.00      0.75         3\n",
            "   subject06       0.00      0.00      0.00         0\n",
            "   subject07       0.83      1.00      0.91         5\n",
            "   subject08       1.00      1.00      1.00         1\n",
            "   subject09       0.50      0.50      0.50         2\n",
            "   subject10       0.33      1.00      0.50         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      0.50      0.67         2\n",
            "   subject13       1.00      1.00      1.00         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.72      0.68      0.66        33\n",
            "weighted avg       0.83      0.76      0.76        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "bvV-AN5trUTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9ae92f-6999-4586-e6e3-6006e85f9abf",
        "id": "lMHC6pG-rUTs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9091\n",
            "F1 Score: 0.9120\n",
            "Precision: 0.9394\n",
            "Recall: 0.9091\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       1.00      1.00      1.00         5\n",
            "   subject03       1.00      1.00      1.00         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       1.00      0.75      0.86         4\n",
            "   subject07       1.00      1.00      1.00         1\n",
            "   subject08       1.00      1.00      1.00         2\n",
            "   subject09       1.00      0.50      0.67         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      1.00      1.00         2\n",
            "   subject14       0.50      1.00      0.67         2\n",
            "   subject15       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.91        33\n",
            "   macro avg       0.82      0.80      0.80        33\n",
            "weighted avg       0.94      0.91      0.91        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-yale-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "K6hcFhntrUTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b15a043-92ec-4575-de2c-f0face681a4a",
        "id": "xchTlBERrUTs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.70\n",
            "F1 Score: 0.63\n",
            "Precision: 0.63\n",
            "Recall: 0.70\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 1 0 1 0 0 0 0 0 0 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       0.83      1.00      0.91         5\n",
            "   subject03       0.00      0.00      0.00         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       0.67      1.00      0.80         4\n",
            "   subject07       0.25      1.00      0.40         1\n",
            "   subject08       0.00      0.00      0.00         2\n",
            "   subject09       0.50      0.50      0.50         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       0.67      1.00      0.80         2\n",
            "   subject13       0.67      1.00      0.80         2\n",
            "   subject14       1.00      1.00      1.00         2\n",
            "   subject15       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.70        33\n",
            "   macro avg       0.54      0.63      0.55        33\n",
            "weighted avg       0.63      0.70      0.63        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset'></a>\n",
        "## LBP (R=1) on ORL Dataset"
      ],
      "metadata": {
        "id": "zfOVVBbF8wnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/ORL_Dataset\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "WS7Bj88F8wnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-svc'></a>\n",
        "### R=1 - ORL dataset : SVC"
      ],
      "metadata": {
        "id": "qBS8e8pe8wnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "J5QqNAHP8wnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d499db-6da1-4fd0-fe20-f82c7ae626fc",
        "id": "FbdfLtRR8wnk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9875\n",
            "F1 Score: 0.9825\n",
            "Precision: 0.9792\n",
            "Recall: 0.9875\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      1.00      1.00         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      1.00      1.00         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       1.00      1.00      1.00         1\n",
            "         s17       1.00      1.00      1.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      1.00      1.00         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      1.00      1.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         1\n",
            "         s29       1.00      1.00      1.00         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       0.00      0.00      0.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       0.67      1.00      0.80         2\n",
            "         s39       1.00      1.00      1.00         1\n",
            "         s40       1.00      1.00      1.00         3\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.96      0.97      0.97        80\n",
            "weighted avg       0.98      0.99      0.98        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "zkMy_Jqa8wnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcb86f5-72fa-431a-cff0-0337f0e0b2bc",
        "id": "z61nsEbk8wnl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8750\n",
            "F1 Score: 0.8988\n",
            "Precision: 0.9656\n",
            "Recall: 0.8750\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      0.75      0.86         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      0.50      0.67         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       0.50      1.00      0.67         1\n",
            "         s17       1.00      0.75      0.86         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      0.60      0.75         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      0.75      0.86         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.25      1.00      0.40         1\n",
            "         s29       1.00      0.50      0.67         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       0.50      1.00      0.67         2\n",
            "         s39       0.50      1.00      0.67         1\n",
            "          s4       0.00      0.00      0.00         0\n",
            "         s40       1.00      0.67      0.80         3\n",
            "          s5       1.00      0.67      0.80         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.92      0.90      0.89        80\n",
            "weighted avg       0.97      0.88      0.90        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "oF3ZlHQz8wnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0baf8e-93ee-48d3-9da1-64081fd30c06",
        "id": "9_tLJFDo8wnl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      1.00      1.00         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      1.00      1.00         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       1.00      1.00      1.00         1\n",
            "         s17       1.00      1.00      1.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      1.00      1.00         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      1.00      1.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         1\n",
            "         s29       1.00      1.00      1.00         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       1.00      1.00      1.00         2\n",
            "         s39       1.00      1.00      1.00         1\n",
            "         s40       1.00      1.00      1.00         3\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-knn'></a>\n",
        "### R=1 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "ntuamHE78wnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b57008-2abc-4e41-9b27-5615fc18a604",
        "id": "EUcG9AJm8wnl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8375\n",
            "F1 Score: 0.8212\n",
            "Precision: 0.8610\n",
            "Recall: 0.8375\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      0.33      0.50         3\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         1\n",
            "         s13       0.50      1.00      0.67         1\n",
            "         s14       0.50      1.00      0.67         3\n",
            "         s15       1.00      1.00      1.00         4\n",
            "         s16       0.75      1.00      0.86         3\n",
            "         s17       1.00      1.00      1.00         2\n",
            "         s18       0.67      1.00      0.80         2\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         2\n",
            "         s24       1.00      1.00      1.00         1\n",
            "         s25       0.00      0.00      0.00         1\n",
            "         s26       1.00      0.75      0.86         4\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.00      0.00      0.00         3\n",
            "         s29       1.00      1.00      1.00         1\n",
            "         s30       0.50      1.00      0.67         1\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         1\n",
            "         s33       1.00      0.50      0.67         6\n",
            "         s34       1.00      1.00      1.00         3\n",
            "         s35       1.00      1.00      1.00         2\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       0.40      1.00      0.57         2\n",
            "         s38       1.00      1.00      1.00         4\n",
            "         s39       0.67      0.50      0.57         4\n",
            "          s4       1.00      1.00      1.00         2\n",
            "         s40       1.00      0.50      0.67         2\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         1\n",
            "          s7       0.33      1.00      0.50         1\n",
            "          s8       1.00      1.00      1.00         2\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.84      0.88      0.83        80\n",
            "weighted avg       0.86      0.84      0.82        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "laLjQMsD8wnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2daf901b-1883-41b4-b192-f8cbf32b0f66",
        "id": "_5yrhoMl8wnl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8625\n",
            "F1 Score: 0.8681\n",
            "Precision: 0.9204\n",
            "Recall: 0.8625\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       0.50      1.00      0.67         1\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       0.67      1.00      0.80         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       0.50      1.00      0.67         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       0.67      0.67      0.67         3\n",
            "         s19       0.00      0.00      0.00         0\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       1.00      1.00      1.00         4\n",
            "         s23       1.00      0.67      0.80         3\n",
            "         s24       1.00      0.50      0.67         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       1.00      0.67      0.80         3\n",
            "         s32       1.00      0.50      0.67         4\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      0.50      0.67         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.60      1.00      0.75         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       1.00      1.00      1.00         2\n",
            "         s40       0.33      0.50      0.40         2\n",
            "          s5       1.00      0.50      0.67         2\n",
            "          s6       0.67      1.00      0.80         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         3\n",
            "          s9       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.86        80\n",
            "   macro avg       0.88      0.86      0.84        80\n",
            "weighted avg       0.92      0.86      0.87        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-orl-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "6F2pwTlU8wnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a805565-b9c1-4ac2-ff1f-686a53b19174",
        "id": "2sIZd9ZL8wnm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8125\n",
            "F1 Score: 0.7941\n",
            "Precision: 0.8171\n",
            "Recall: 0.8125\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 2 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         1\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      0.67      0.80         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       0.67      1.00      0.80         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       1.00      1.00      1.00         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       1.00      0.67      0.80         3\n",
            "         s19       0.00      0.00      0.00         0\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       0.80      1.00      0.89         4\n",
            "         s23       0.50      0.33      0.40         3\n",
            "         s24       1.00      1.00      1.00         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       0.00      0.00      0.00         3\n",
            "         s32       0.75      0.75      0.75         4\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       0.50      1.00      0.67         2\n",
            "         s35       0.50      0.50      0.50         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.75      1.00      0.86         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       1.00      0.50      0.67         2\n",
            "         s40       0.00      0.00      0.00         2\n",
            "          s5       1.00      0.50      0.67         2\n",
            "          s6       0.50      1.00      0.67         2\n",
            "          s7       0.50      1.00      0.67         1\n",
            "          s8       0.75      1.00      0.86         3\n",
            "          s9       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.81        80\n",
            "   macro avg       0.80      0.81      0.78        80\n",
            "weighted avg       0.82      0.81      0.79        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aX7kCOvQ1_1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset'></a>\n",
        "## LBP (R=1) on LFW Dataset"
      ],
      "metadata": {
        "id": "ZlA4YJB-2pV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/lfw100\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "MKpJnE812pV9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-svc'></a>\n",
        "### R=1 - LFW dataset : SVC"
      ],
      "metadata": {
        "id": "00tRzoe12pV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "Pn2G1qfa2pV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79727eb8-3c38-420a-97b6-3403db19d9fb",
        "id": "xlN_z6172pV-"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0467\n",
            "Precision: 0.0581\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.09      1.00      0.16         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "skw9SHCv2pV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5fd95c-f00a-4128-bd22-fe05b742293f",
        "id": "JU-kEdjb2pV-"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0110\n",
            "Precision: 0.0059\n",
            "Recall: 0.0769\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.08      1.00      0.14         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       0.00      0.00      0.00         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.08        39\n",
            "           macro avg       0.00      0.03      0.00        39\n",
            "        weighted avg       0.01      0.08      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "60jcp_5g2pV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a711dd-2af2-45a1-8b53-d32516f90e6e",
        "id": "_ZJKm0kV2pV_"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0478\n",
            "Precision: 0.0587\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.10      1.00      0.18         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-knn'></a>\n",
        "### R=1 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "YUu1_-c32pV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8520191-5b9a-45a0-b361-01c18af81d8b",
        "id": "OgOSX-_a2pV_"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0256\n",
            "F1 Score: 0.0114\n",
            "Precision: 0.0073\n",
            "Recall: 0.0256\n",
            "Classification Report:\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "                     AJ_Cook       0.00      0.00      0.00         1\n",
            "                 Aaron_Guiel       0.00      0.00      0.00         1\n",
            "             Aaron_Patterson       0.00      0.00      0.00         1\n",
            "                  Aaron_Pena       0.00      0.00      0.00         0\n",
            "                Aaron_Tippin       0.00      0.00      0.00         1\n",
            "         Abdel_Aziz_Al-Hakim       0.00      0.00      0.00         0\n",
            "          Abdel_Madi_Shabneh       0.00      0.00      0.00         0\n",
            "         Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "      Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "                    Abdullah       0.00      0.00      0.00         1\n",
            "                Abdullah_Gul       0.14      0.50      0.22         2\n",
            "            Abdullah_Nasseef       0.00      0.00      0.00         1\n",
            "            Abdullatif_Sener       0.00      0.00      0.00         1\n",
            "                Abel_Aguilar       0.00      0.00      0.00         1\n",
            "                Abel_Pacheco       0.00      0.00      0.00         1\n",
            "Abid_Hamid_Mahmud_Al-Tikriti       0.00      0.00      0.00         0\n",
            "                    Adam_Ant       0.00      0.00      0.00         0\n",
            "                Adam_Sandler       0.00      0.00      0.00         2\n",
            "                  Adam_Scott       0.00      0.00      0.00         1\n",
            "               Adelina_Avila       0.00      0.00      0.00         1\n",
            "       Adolfo_Aguilar_Zinser       0.00      0.00      0.00         1\n",
            "        Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "            Adrian_McPherson       0.00      0.00      0.00         0\n",
            "              Adrian_Nastase       0.00      0.00      0.00         0\n",
            "       Adriana_Perez_Navarro       0.00      0.00      0.00         0\n",
            "              Adrianna_Zuzic       0.00      0.00      0.00         0\n",
            "                Adrien_Brody       0.00      0.00      0.00         4\n",
            "              Agnelo_Queiroz       0.00      0.00      0.00         1\n",
            "                Ahmad_Masood       0.00      0.00      0.00         2\n",
            "                 Ahmed_Ahmed       0.00      0.00      0.00         1\n",
            "               Ahmed_Chalabi       0.00      0.00      0.00         2\n",
            "         Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         0\n",
            "                 Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "                Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "          Ahmet_Necdet_Sezer       0.00      0.00      0.00         1\n",
            "              Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "                 Aidan_Quinn       0.00      0.00      0.00         0\n",
            "              Ainsworth_Dyer       0.00      0.00      0.00         1\n",
            "    Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         0\n",
            "              Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "              Akiko_Morigami       0.00      0.00      0.00         0\n",
            "                    Al_Davis       0.00      0.00      0.00         1\n",
            "                     Al_Gore       0.00      0.00      0.00         0\n",
            "                 Al_Sharpton       0.00      0.00      0.00         1\n",
            "              Alan_Greenspan       0.00      0.00      0.00         1\n",
            "            Alan_Stonecipher       0.00      0.00      0.00         0\n",
            "               Alan_Trammell       0.00      0.00      0.00         1\n",
            "\n",
            "                    accuracy                           0.03        39\n",
            "                   macro avg       0.00      0.01      0.00        39\n",
            "                weighted avg       0.01      0.03      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "m43zt8du2pV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85db3bb-34cc-495f-f863-97029101c61c",
        "id": "vmAxzAf32pV_"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1538\n",
            "F1 Score: 0.1251\n",
            "Precision: 0.1103\n",
            "Recall: 0.1538\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.29      0.40      0.33         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "                Adam_Ant       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "              Adam_Scott       0.00      0.00      0.00         0\n",
            "          Adel_Al-Jubeir       0.50      1.00      0.67         1\n",
            "    Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.12      0.33      0.18         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "      Ahmet_Necdet_Sezer       0.00      0.00      0.00         0\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       1.00      1.00      1.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "                 Al_Gore       0.25      0.25      0.25         4\n",
            "             Al_Sharpton       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.15        39\n",
            "               macro avg       0.07      0.09      0.07        39\n",
            "            weighted avg       0.11      0.15      0.13        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-1-lfw-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "EKMkzxT32pWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f668ec20-68b6-4237-e74e-0cf936c598d4",
        "id": "e8OM58jc2pWA"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0403\n",
            "Precision: 0.0342\n",
            "Recall: 0.0769\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "           Aaron_Eckhart       0.00      0.00      0.00         0\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "            Abdul_Rahman       0.00      0.00      0.00         0\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.00      0.00      0.00         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "               Adam_Mair       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "          Adel_Al-Jubeir       0.00      0.00      0.00         1\n",
            "    Adolfo_Rodriguez_Saa       1.00      1.00      1.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "            Adriana_Lima       0.00      0.00      0.00         0\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.00      0.00      0.00         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "            Aiysha_Smith       0.00      0.00      0.00         0\n",
            "          Akbar_Al_Baker       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.17      1.00      0.29         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "          Akiko_Morigami       0.00      0.00      0.00         0\n",
            "             Akmal_Taher       0.00      0.00      0.00         0\n",
            "             Al_Cardenas       0.00      0.00      0.00         0\n",
            "                 Al_Gore       0.00      0.00      0.00         4\n",
            "               Al_Leiter       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "           Alain_Ducasse       0.00      0.00      0.00         0\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.08        39\n",
            "               macro avg       0.03      0.05      0.03        39\n",
            "            weighted avg       0.03      0.08      0.04        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbWJioGW2pWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2'></a>\n",
        "# LBP (R=2)"
      ],
      "metadata": {
        "id": "k0sLKdCeqZZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skimage import feature\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def get_lbp_features_2(image, radius=2, n_points=8):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate LBP features\n",
        "    # lbp = feature.local_binary_pattern(gray, n_points, radius, method=\"uniform\")\n",
        "    lbp = LBP(gray,n_points,radius)\n",
        "\n",
        "    # Calculate a histogram of the LBP features\n",
        "    grid_x = 16\n",
        "    grid_y = 16\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    height, width, channel = image.shape\n",
        "\n",
        "    # Calculate the size of each grid\n",
        "    grid_height = height // grid_y\n",
        "    grid_width = width // grid_x\n",
        "\n",
        "    # Initialize an empty list to store the histograms\n",
        "    histograms = []\n",
        "\n",
        "    # Loop through the grids\n",
        "    for i in range(grid_y):\n",
        "        for j in range(grid_x):\n",
        "            # Get the sub-image of the current grid\n",
        "            sub_img = lbp[i * grid_height:(i + 1) * grid_height, j * grid_width:(j + 1) * grid_width]\n",
        "\n",
        "            # Compute the histogram of the sub-image\n",
        "            hist, bins = np.histogram(sub_img, bins=256, range=(0, 255))\n",
        "            histograms.append(hist)\n",
        "\n",
        "    # Concatenate the histograms into a single array\n",
        "    final_histogram = np.concatenate(histograms)\n",
        "\n",
        "    hist = np.array(final_histogram)\n",
        "    # Normalize the histogram\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "dQJRc8EJqZZK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset'></a>\n",
        "## LBP (R=2) on KSV Dataset"
      ],
      "metadata": {
        "id": "Nd9y50-5qZZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for image_file in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "            lbp_features = get_lbp_features_2(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/KSV_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "BLUsDz9QqZZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-svc'></a>\n",
        "### R=2 - KSV dataset : SVC"
      ],
      "metadata": {
        "id": "i3QZTQQXqZZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "cE244ZJVqZZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706b1f6c-eeb6-48dc-b286-e79430041a03",
        "id": "sNODEhbpqZZM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6061\n",
            "F1 Score: 0.5980\n",
            "Precision: 0.7394\n",
            "Recall: 0.6061\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.40      0.57         5\n",
            "  21BEIT30044       0.80      1.00      0.89         4\n",
            "  21BEIT30048       0.25      0.50      0.33         2\n",
            "  21BEIT30053       0.50      0.50      0.50         2\n",
            "  21BEIT30090       0.67      0.67      0.67         3\n",
            "  21BEIT30092       0.50      1.00      0.67         2\n",
            "  21BEIT30100       0.50      0.50      0.50         2\n",
            "  21BEIT30105       0.80      1.00      0.89         4\n",
            "  21BEIT30128       1.00      0.25      0.40         4\n",
            "  21BEIT30135       0.25      0.50      0.33         2\n",
            "222SBEIT30014       1.00      0.33      0.50         3\n",
            "\n",
            "     accuracy                           0.61        33\n",
            "    macro avg       0.66      0.60      0.57        33\n",
            " weighted avg       0.74      0.61      0.60        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "cvjqdKl0qZZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafde511-0f12-434c-de8a-71b87cb84f68",
        "id": "LeZNspgHqZZN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3939\n",
            "F1 Score: 0.3453\n",
            "Precision: 0.3630\n",
            "Recall: 0.3939\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         5\n",
            "  21BEIT30044       0.75      0.75      0.75         4\n",
            "  21BEIT30048       0.10      0.50      0.17         2\n",
            "  21BEIT30053       1.00      0.50      0.67         2\n",
            "  21BEIT30090       1.00      0.67      0.80         3\n",
            "  21BEIT30092       0.22      1.00      0.36         2\n",
            "  21BEIT30100       0.67      1.00      0.80         2\n",
            "  21BEIT30105       0.50      0.50      0.50         4\n",
            "  21BEIT30128       0.00      0.00      0.00         4\n",
            "  21BEIT30135       0.00      0.00      0.00         2\n",
            "222SBEIT30014       0.00      0.00      0.00         3\n",
            "\n",
            "     accuracy                           0.39        33\n",
            "    macro avg       0.39      0.45      0.37        33\n",
            " weighted avg       0.36      0.39      0.35        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "MK5tyT7kqZZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c68cdc81-b733-41eb-cdec-65cc50b647a6",
        "id": "73EsgYdTqZZN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6667\n",
            "F1 Score: 0.6640\n",
            "Precision: 0.7788\n",
            "Recall: 0.6667\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.40      0.57         5\n",
            "  21BEIT30044       1.00      1.00      1.00         4\n",
            "  21BEIT30048       0.25      0.50      0.33         2\n",
            "  21BEIT30053       0.50      0.50      0.50         2\n",
            "  21BEIT30090       0.67      0.67      0.67         3\n",
            "  21BEIT30092       0.50      1.00      0.67         2\n",
            "  21BEIT30100       0.50      0.50      0.50         2\n",
            "  21BEIT30105       0.80      1.00      0.89         4\n",
            "  21BEIT30128       1.00      0.50      0.67         4\n",
            "  21BEIT30135       0.50      1.00      0.67         2\n",
            "222SBEIT30014       1.00      0.33      0.50         3\n",
            "\n",
            "     accuracy                           0.67        33\n",
            "    macro avg       0.70      0.67      0.63        33\n",
            " weighted avg       0.78      0.67      0.66        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-knn'></a>\n",
        "### R=2 - KSV dataset : KNN"
      ],
      "metadata": {
        "id": "nuoVsaYlqZZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d7646a-dced-4e3a-f38a-97d81a7679df",
        "id": "GXPSK6vpqZZO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2727\n",
            "F1 Score: 0.2139\n",
            "Precision: 0.2533\n",
            "Recall: 0.2727\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         3\n",
            "  21BEIT30044       0.67      1.00      0.80         2\n",
            "  21BEIT30048       0.23      1.00      0.38         3\n",
            "  21BEIT30053       0.33      0.33      0.33         3\n",
            "  21BEIT30090       0.00      0.00      0.00         3\n",
            "  21BEIT30092       0.00      0.00      0.00         2\n",
            "  21BEIT30100       0.00      0.00      0.00         3\n",
            "  21BEIT30105       0.17      0.50      0.25         2\n",
            "  21BEIT30128       0.50      0.17      0.25         6\n",
            "  21BEIT30135       0.50      0.25      0.33         4\n",
            "222SBEIT30014       0.00      0.00      0.00         2\n",
            "\n",
            "     accuracy                           0.27        33\n",
            "    macro avg       0.22      0.30      0.21        33\n",
            " weighted avg       0.25      0.27      0.21        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "pBIU6uwhqZZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2749f50d-0da8-44e3-dcbc-0304f7916db1",
        "id": "C-KbWhdGqZZP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3939\n",
            "F1 Score: 0.3583\n",
            "Precision: 0.3582\n",
            "Recall: 0.3939\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 0 1 0 0 0 1 0 1]\n",
            " [0 4 1 0 0 0 1 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 2 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 1 0 0 1 0 0 0 0 4 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         3\n",
            "  21BEIT30044       0.80      0.67      0.73         6\n",
            "  21BEIT30048       0.67      0.50      0.57         4\n",
            "  21BEIT30053       0.67      0.67      0.67         3\n",
            "  21BEIT30090       0.40      1.00      0.57         2\n",
            "  21BEIT30092       0.00      0.00      0.00         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.33      0.50      0.40         2\n",
            "  21BEIT30128       0.00      0.00      0.00         1\n",
            "  21BEIT30135       0.22      0.50      0.31         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.39        33\n",
            "    macro avg       0.28      0.35      0.29        33\n",
            " weighted avg       0.36      0.39      0.36        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-ksv-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "zhPY63bpqZZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3e2b31-67d2-4d65-8060-0708bf04e7bf",
        "id": "w0R-5GaFqZZP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.39\n",
            "F1 Score: 0.36\n",
            "Precision: 0.39\n",
            "Recall: 0.39\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 5 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 2 0 0 1 0 0 0 1 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 1 0 3 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 2 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.50      0.67      0.57         3\n",
            "  21BEIT30044       0.56      0.83      0.67         6\n",
            "  21BEIT30048       0.67      0.50      0.57         4\n",
            "  21BEIT30053       1.00      0.33      0.50         3\n",
            "  21BEIT30090       1.00      1.00      1.00         2\n",
            "  21BEIT30092       0.00      0.00      0.00         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.17      0.50      0.25         2\n",
            "  21BEIT30128       0.00      0.00      0.00         1\n",
            "  21BEIT30135       0.00      0.00      0.00         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.39        33\n",
            "    macro avg       0.35      0.35      0.32        33\n",
            " weighted avg       0.39      0.39      0.36        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset'></a>\n",
        "## LBP (R=2) on Yale Dataset"
      ],
      "metadata": {
        "id": "DT7tuBfnx8kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for gif_file in os.listdir(class_path):\n",
        "            gif_path = os.path.join(class_path, gif_file)\n",
        "\n",
        "            gif_image = Image.open(gif_path)\n",
        "            rgb_image = gif_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features_2(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/Yale_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "4PbW8l0wx8kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-svc'></a>\n",
        "### R=2 - Yale dataset : SVC"
      ],
      "metadata": {
        "id": "88IygQcex8ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "S5qcTIXDx8ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15b53b5-0651-4ca2-b289-8ec201a35b8b",
        "id": "viQBtXgtx8ka"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7879\n",
            "F1 Score: 0.8079\n",
            "Precision: 0.9394\n",
            "Recall: 0.7879\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.33      1.00      0.50         1\n",
            "   subject04       1.00      1.00      1.00         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       1.00      1.00      1.00         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       1.00      1.00      1.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.33      1.00      0.50         2\n",
            "\n",
            "    accuracy                           0.79        33\n",
            "   macro avg       0.84      0.79      0.77        33\n",
            "weighted avg       0.94      0.79      0.81        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "lG21OcY7x8ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bd6ca6-8470-4bf1-83f7-674d7bd834f7",
        "id": "IPnROdNEx8ka"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6364\n",
            "F1 Score: 0.6632\n",
            "Precision: 0.8838\n",
            "Recall: 0.6364\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.33      0.50         3\n",
            "   subject03       1.00      1.00      1.00         1\n",
            "   subject04       1.00      1.00      1.00         5\n",
            "   subject05       1.00      0.50      0.67         2\n",
            "   subject06       0.17      1.00      0.29         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       0.50      1.00      0.67         2\n",
            "   subject13       1.00      0.50      0.67         4\n",
            "   subject14       1.00      0.33      0.50         3\n",
            "   subject15       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.64        33\n",
            "   macro avg       0.74      0.63      0.60        33\n",
            "weighted avg       0.88      0.64      0.66        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "-zaUB3qZx8ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d5a657-3622-4edf-f67c-d463a9dd902a",
        "id": "IRJ08z0ex8ka"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7879\n",
            "F1 Score: 0.7985\n",
            "Precision: 0.9182\n",
            "Recall: 0.7879\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.33      1.00      0.50         1\n",
            "   subject04       0.83      1.00      0.91         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       1.00      1.00      1.00         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       1.00      1.00      1.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.79        33\n",
            "   macro avg       0.84      0.79      0.77        33\n",
            "weighted avg       0.92      0.79      0.80        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-knn'></a>\n",
        "### R=2 - Yale dataset : KNN"
      ],
      "metadata": {
        "id": "ML4s6Xrlx8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f302b2-d5fa-4c30-c2ac-5e3c597b0dfe",
        "id": "X-DXGdR5x8kb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7576\n",
            "F1 Score: 0.7732\n",
            "Precision: 0.8672\n",
            "Recall: 0.7576\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       0.00      0.00      0.00         1\n",
            "   subject03       1.00      0.50      0.67         2\n",
            "   subject04       1.00      0.50      0.67         4\n",
            "   subject05       0.75      1.00      0.86         3\n",
            "   subject06       0.00      0.00      0.00         0\n",
            "   subject07       0.83      1.00      0.91         5\n",
            "   subject08       1.00      1.00      1.00         1\n",
            "   subject09       0.50      0.50      0.50         2\n",
            "   subject10       0.20      1.00      0.33         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      0.50      0.67         2\n",
            "   subject13       1.00      1.00      1.00         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.75      0.68      0.67        33\n",
            "weighted avg       0.87      0.76      0.77        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "3rkFp_Mgx8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a190e35-1a33-4baa-a141-5c3ca0b5b351",
        "id": "_KaJO9I8x8kb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8182\n",
            "F1 Score: 0.8219\n",
            "Precision: 0.8990\n",
            "Recall: 0.8182\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 1 1 0 0 0 0 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       1.00      1.00      1.00         5\n",
            "   subject03       1.00      0.75      0.86         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       1.00      0.75      0.86         4\n",
            "   subject07       0.33      1.00      0.50         1\n",
            "   subject08       0.67      1.00      0.80         2\n",
            "   subject09       1.00      0.50      0.67         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      1.00      1.00         2\n",
            "   subject14       0.50      1.00      0.67         2\n",
            "   subject15       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.82        33\n",
            "   macro avg       0.75      0.74      0.70        33\n",
            "weighted avg       0.90      0.82      0.82        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-yale-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "V2mjGGGQx8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebeec2ab-001a-42dc-9ad8-70ac84dc5021",
        "id": "F24COH9nx8kb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6667\n",
            "F1 Score: 0.5899\n",
            "Precision: 0.5804\n",
            "Recall: 0.6667\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 1 0 1 0 0 0 0 0 0 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       0.71      1.00      0.83         5\n",
            "   subject03       0.00      0.00      0.00         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       0.67      1.00      0.80         4\n",
            "   subject07       0.25      1.00      0.40         1\n",
            "   subject08       0.00      0.00      0.00         2\n",
            "   subject09       0.00      0.00      0.00         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       0.67      1.00      0.80         2\n",
            "   subject14       0.67      1.00      0.80         2\n",
            "   subject15       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.67        33\n",
            "   macro avg       0.50      0.60      0.51        33\n",
            "weighted avg       0.58      0.67      0.59        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset'></a>\n",
        "## LBP (R=2) on ORL Dataset"
      ],
      "metadata": {
        "id": "8s8opxRd9xmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features_2(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/ORL_Dataset\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "mZk08CWd9xmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-svc'></a>\n",
        "### R=2 - ORL dataset : SVC"
      ],
      "metadata": {
        "id": "37F4iQ6p9xmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "U56sWS6e9xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ3Xi_Z-9xmE",
        "outputId": "1c13e148-3cda-4fca-b682-9931857aaafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8750\n",
            "F1 Score: 0.9001\n",
            "Precision: 0.9635\n",
            "Recall: 0.8750\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      0.75      0.86         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      0.50      0.67         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       0.50      1.00      0.67         1\n",
            "         s17       1.00      0.50      0.67         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      0.60      0.75         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      0.75      0.86         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.25      1.00      0.40         1\n",
            "         s29       1.00      1.00      1.00         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       0.67      1.00      0.80         2\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       0.00      0.00      0.00         0\n",
            "         s40       1.00      0.67      0.80         3\n",
            "          s5       0.67      0.67      0.67         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.93      0.91      0.90        80\n",
            "weighted avg       0.96      0.88      0.90        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "hgulj9bC9xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQEPWdPL9xmE",
        "outputId": "07c4c823-db77-4e46-b468-6dea601c9a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5250\n",
            "F1 Score: 0.5264\n",
            "Precision: 0.5694\n",
            "Recall: 0.5250\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       0.00      0.00      0.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       0.00      0.00      0.00         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       0.00      0.00      0.00         4\n",
            "         s15       1.00      0.50      0.67         2\n",
            "         s16       0.10      1.00      0.18         1\n",
            "         s17       0.00      0.00      0.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       0.00      0.00      0.00         2\n",
            "         s20       0.00      0.00      0.00         5\n",
            "         s21       0.00      0.00      0.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      0.67      0.80         3\n",
            "         s24       0.00      0.00      0.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s26       0.00      0.00      0.00         0\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.25      1.00      0.40         1\n",
            "         s29       1.00      0.50      0.67         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      0.67      0.80         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       1.00      1.00      1.00         2\n",
            "         s39       0.20      1.00      0.33         1\n",
            "          s4       0.00      0.00      0.00         0\n",
            "         s40       0.00      0.00      0.00         3\n",
            "          s5       1.00      0.67      0.80         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.53        80\n",
            "   macro avg       0.66      0.66      0.63        80\n",
            "weighted avg       0.57      0.53      0.53        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "OKHAGR9l9xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL1L3ZTT9xmE",
        "outputId": "6482ad2e-729a-46c0-bdf3-415b9c15a862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9625\n",
            "F1 Score: 0.9692\n",
            "Precision: 0.9854\n",
            "Recall: 0.9625\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      1.00      1.00         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      0.75      0.86         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       1.00      1.00      1.00         1\n",
            "         s17       1.00      1.00      1.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      0.80      0.89         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      1.00      1.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.50      1.00      0.67         1\n",
            "         s29       1.00      1.00      1.00         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       0.67      1.00      0.80         2\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       0.00      0.00      0.00         0\n",
            "         s40       1.00      1.00      1.00         3\n",
            "          s5       1.00      0.67      0.80         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.95      0.95      0.95        80\n",
            "weighted avg       0.99      0.96      0.97        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-knn'></a>\n",
        "### R=2 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "bARcd7F99xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hscU5HDx9xmE",
        "outputId": "94136268-0c77-42bc-d8a4-af17b0e1413e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8250\n",
            "F1 Score: 0.8085\n",
            "Precision: 0.8642\n",
            "Recall: 0.8250\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      0.67      0.80         3\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         1\n",
            "         s13       0.50      1.00      0.67         1\n",
            "         s14       0.50      1.00      0.67         3\n",
            "         s15       1.00      1.00      1.00         4\n",
            "         s16       1.00      1.00      1.00         3\n",
            "         s17       1.00      1.00      1.00         2\n",
            "         s18       0.67      1.00      0.80         2\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         2\n",
            "         s24       1.00      1.00      1.00         1\n",
            "         s25       0.00      0.00      0.00         1\n",
            "         s26       1.00      0.25      0.40         4\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.00      0.00      0.00         3\n",
            "         s29       1.00      1.00      1.00         1\n",
            "         s30       0.33      1.00      0.50         1\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         1\n",
            "         s33       1.00      0.50      0.67         6\n",
            "         s34       1.00      1.00      1.00         3\n",
            "         s35       1.00      0.50      0.67         2\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       0.40      1.00      0.57         2\n",
            "         s38       1.00      1.00      1.00         4\n",
            "         s39       0.75      0.75      0.75         4\n",
            "          s4       1.00      1.00      1.00         2\n",
            "         s40       1.00      0.50      0.67         2\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         1\n",
            "          s7       0.33      1.00      0.50         1\n",
            "          s8       1.00      1.00      1.00         2\n",
            "          s9       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.84      0.87      0.82        80\n",
            "weighted avg       0.86      0.82      0.81        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "iwUBLxLi9xmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__0N7oU9xmE",
        "outputId": "f64b9ac7-91d2-4c6e-bb24-12fd4d3a3c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8250\n",
            "F1 Score: 0.8288\n",
            "Precision: 0.8917\n",
            "Recall: 0.8250\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       0.33      1.00      0.50         1\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       0.50      1.00      0.67         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       1.00      1.00      1.00         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       1.00      0.67      0.80         3\n",
            "         s19       0.00      0.00      0.00         0\n",
            "          s2       1.00      0.67      0.80         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       1.00      1.00      1.00         4\n",
            "         s23       1.00      0.33      0.50         3\n",
            "         s24       0.00      0.00      0.00         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       0.50      1.00      0.67         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       1.00      0.67      0.80         3\n",
            "         s32       1.00      0.50      0.67         4\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      0.50      0.67         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.75      1.00      0.86         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       0.67      1.00      0.80         2\n",
            "         s40       0.33      0.50      0.40         2\n",
            "          s5       0.50      0.50      0.50         2\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         3\n",
            "          s9       0.25      1.00      0.40         1\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.83      0.82      0.80        80\n",
            "weighted avg       0.89      0.82      0.83        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-orl-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "WNkQOzd59xmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiqrjtVk9xmF",
        "outputId": "89ce9b1c-18e9-49e1-a742-41805e142ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n",
            "F1 Score: 0.82\n",
            "Precision: 0.83\n",
            "Recall: 0.84\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         1\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       1.00      1.00      1.00         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       1.00      1.00      1.00         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       1.00      0.67      0.80         3\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       0.80      1.00      0.89         4\n",
            "         s23       1.00      0.67      0.80         3\n",
            "         s24       1.00      1.00      1.00         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.67      1.00      0.80         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       0.00      0.00      0.00         3\n",
            "         s32       0.75      0.75      0.75         4\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       0.50      1.00      0.67         2\n",
            "         s35       0.50      0.50      0.50         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.75      1.00      0.86         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       1.00      0.50      0.67         2\n",
            "         s40       0.00      0.00      0.00         2\n",
            "          s5       0.50      0.50      0.50         2\n",
            "          s6       0.67      1.00      0.80         2\n",
            "          s7       0.50      1.00      0.67         1\n",
            "          s8       0.75      1.00      0.86         3\n",
            "          s9       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.83      0.85      0.82        80\n",
            "weighted avg       0.83      0.84      0.82        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2a8AOkBTCh72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset'></a>\n",
        "## LBP (R=2) on LFW Dataset"
      ],
      "metadata": {
        "id": "P0FLRz7UCih1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/lfw100\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "UD0KKvM0Cih2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-svc'></a>\n",
        "### R=2 - LFW dataset : SVC"
      ],
      "metadata": {
        "id": "Nma2xB73Cih2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "urWuF5XACih2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2924bb-d943-4335-9333-62af3a112114",
        "id": "V_sRhjy9Cih2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0467\n",
            "Precision: 0.0581\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.09      1.00      0.16         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "K81odj9PCih2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ca8707-cc88-4d85-c358-b87c79f970ed",
        "id": "hSREShvOCih2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0110\n",
            "Precision: 0.0059\n",
            "Recall: 0.0769\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.08      1.00      0.14         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       0.00      0.00      0.00         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.08        39\n",
            "           macro avg       0.00      0.03      0.00        39\n",
            "        weighted avg       0.01      0.08      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "vNYXylEECih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb046666-5ccc-4c81-cc1d-b12bd37b47d5",
        "id": "UtS7UFmECih3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0478\n",
            "Precision: 0.0587\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.10      1.00      0.18         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-knn'></a>\n",
        "### R=2 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "mEzVPWDqCih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2713f635-895e-40e6-b82d-6c34d8f39995",
        "id": "kxYmwOLnCih3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0256\n",
            "F1 Score: 0.0114\n",
            "Precision: 0.0073\n",
            "Recall: 0.0256\n",
            "Classification Report:\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "                     AJ_Cook       0.00      0.00      0.00         1\n",
            "                 Aaron_Guiel       0.00      0.00      0.00         1\n",
            "             Aaron_Patterson       0.00      0.00      0.00         1\n",
            "                  Aaron_Pena       0.00      0.00      0.00         0\n",
            "                Aaron_Tippin       0.00      0.00      0.00         1\n",
            "         Abdel_Aziz_Al-Hakim       0.00      0.00      0.00         0\n",
            "          Abdel_Madi_Shabneh       0.00      0.00      0.00         0\n",
            "         Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "      Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "                    Abdullah       0.00      0.00      0.00         1\n",
            "                Abdullah_Gul       0.14      0.50      0.22         2\n",
            "            Abdullah_Nasseef       0.00      0.00      0.00         1\n",
            "            Abdullatif_Sener       0.00      0.00      0.00         1\n",
            "                Abel_Aguilar       0.00      0.00      0.00         1\n",
            "                Abel_Pacheco       0.00      0.00      0.00         1\n",
            "Abid_Hamid_Mahmud_Al-Tikriti       0.00      0.00      0.00         0\n",
            "                    Adam_Ant       0.00      0.00      0.00         0\n",
            "                Adam_Sandler       0.00      0.00      0.00         2\n",
            "                  Adam_Scott       0.00      0.00      0.00         1\n",
            "               Adelina_Avila       0.00      0.00      0.00         1\n",
            "       Adolfo_Aguilar_Zinser       0.00      0.00      0.00         1\n",
            "        Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "            Adrian_McPherson       0.00      0.00      0.00         0\n",
            "              Adrian_Nastase       0.00      0.00      0.00         0\n",
            "       Adriana_Perez_Navarro       0.00      0.00      0.00         0\n",
            "              Adrianna_Zuzic       0.00      0.00      0.00         0\n",
            "                Adrien_Brody       0.00      0.00      0.00         4\n",
            "              Agnelo_Queiroz       0.00      0.00      0.00         1\n",
            "                Ahmad_Masood       0.00      0.00      0.00         2\n",
            "                 Ahmed_Ahmed       0.00      0.00      0.00         1\n",
            "               Ahmed_Chalabi       0.00      0.00      0.00         2\n",
            "         Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         0\n",
            "                 Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "                Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "          Ahmet_Necdet_Sezer       0.00      0.00      0.00         1\n",
            "              Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "                 Aidan_Quinn       0.00      0.00      0.00         0\n",
            "              Ainsworth_Dyer       0.00      0.00      0.00         1\n",
            "    Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         0\n",
            "              Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "              Akiko_Morigami       0.00      0.00      0.00         0\n",
            "                    Al_Davis       0.00      0.00      0.00         1\n",
            "                     Al_Gore       0.00      0.00      0.00         0\n",
            "                 Al_Sharpton       0.00      0.00      0.00         1\n",
            "              Alan_Greenspan       0.00      0.00      0.00         1\n",
            "            Alan_Stonecipher       0.00      0.00      0.00         0\n",
            "               Alan_Trammell       0.00      0.00      0.00         1\n",
            "\n",
            "                    accuracy                           0.03        39\n",
            "                   macro avg       0.00      0.01      0.00        39\n",
            "                weighted avg       0.01      0.03      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "PVUj5eLiCih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecad8ec-c177-4aef-8096-22fd25db2ab1",
        "id": "gwKoelTrCih3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1538\n",
            "F1 Score: 0.1251\n",
            "Precision: 0.1103\n",
            "Recall: 0.1538\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.29      0.40      0.33         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "                Adam_Ant       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "              Adam_Scott       0.00      0.00      0.00         0\n",
            "          Adel_Al-Jubeir       0.50      1.00      0.67         1\n",
            "    Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.12      0.33      0.18         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "      Ahmet_Necdet_Sezer       0.00      0.00      0.00         0\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       1.00      1.00      1.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "                 Al_Gore       0.25      0.25      0.25         4\n",
            "             Al_Sharpton       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.15        39\n",
            "               macro avg       0.07      0.09      0.07        39\n",
            "            weighted avg       0.11      0.15      0.13        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-2-lfw-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "g01a-4FCCih3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e184c639-b504-49cf-8f6a-4989fa29a128",
        "id": "HH_r8oVMCih3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0403\n",
            "Precision: 0.0342\n",
            "Recall: 0.0769\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "           Aaron_Eckhart       0.00      0.00      0.00         0\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "            Abdul_Rahman       0.00      0.00      0.00         0\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.00      0.00      0.00         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "               Adam_Mair       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "          Adel_Al-Jubeir       0.00      0.00      0.00         1\n",
            "    Adolfo_Rodriguez_Saa       1.00      1.00      1.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "            Adriana_Lima       0.00      0.00      0.00         0\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.00      0.00      0.00         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "            Aiysha_Smith       0.00      0.00      0.00         0\n",
            "          Akbar_Al_Baker       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.17      1.00      0.29         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "          Akiko_Morigami       0.00      0.00      0.00         0\n",
            "             Akmal_Taher       0.00      0.00      0.00         0\n",
            "             Al_Cardenas       0.00      0.00      0.00         0\n",
            "                 Al_Gore       0.00      0.00      0.00         4\n",
            "               Al_Leiter       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "           Alain_Ducasse       0.00      0.00      0.00         0\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.08        39\n",
            "               macro avg       0.03      0.05      0.03        39\n",
            "            weighted avg       0.03      0.08      0.04        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1sXoylnCih4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3'></a>\n",
        "# LBP (R=3)"
      ],
      "metadata": {
        "id": "8C-IL-mrHaD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from skimage import feature\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def get_lbp_features_3(image, radius=3, n_points=8):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate LBP features\n",
        "    # lbp = feature.local_binary_pattern(gray, n_points, radius, method=\"uniform\")\n",
        "    lbp = LBP(gray,n_points,radius)\n",
        "\n",
        "    # Calculate a histogram of the LBP features\n",
        "    grid_x = 16\n",
        "    grid_y = 16\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    height, width, channel = image.shape\n",
        "\n",
        "    # Calculate the size of each grid\n",
        "    grid_height = height // grid_y\n",
        "    grid_width = width // grid_x\n",
        "\n",
        "    # Initialize an empty list to store the histograms\n",
        "    histograms = []\n",
        "\n",
        "    # Loop through the grids\n",
        "    for i in range(grid_y):\n",
        "        for j in range(grid_x):\n",
        "            # Get the sub-image of the current grid\n",
        "            sub_img = lbp[i * grid_height:(i + 1) * grid_height, j * grid_width:(j + 1) * grid_width]\n",
        "\n",
        "            # Compute the histogram of the sub-image\n",
        "            hist, bins = np.histogram(sub_img, bins=256, range=(0, 255))\n",
        "            histograms.append(hist)\n",
        "\n",
        "    # Concatenate the histograms into a single array\n",
        "    final_histogram = np.concatenate(histograms)\n",
        "\n",
        "    hist = np.array(final_histogram)\n",
        "    # Normalize the histogram\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "QryAhap3HaD7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset'></a>\n",
        "## LBP (R=3) on KSV Dataset"
      ],
      "metadata": {
        "id": "LX6Kg12EHaD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for image_file in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "            lbp_features = get_lbp_features_3(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/KSV_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "PN8HwFfQHaD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-svc'></a>\n",
        "### R=3 - KSV dataset : SVC"
      ],
      "metadata": {
        "id": "z9Y7glCeHaD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "LI_il3y3HaD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d64a85c-fd01-473f-e4d8-a84fa67c0f3a",
        "id": "oNr46tj_HaD7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5152\n",
            "F1 Score: 0.4626\n",
            "Precision: 0.5951\n",
            "Recall: 0.5152\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.20      0.33         5\n",
            "  21BEIT30044       0.80      1.00      0.89         4\n",
            "  21BEIT30048       0.33      0.50      0.40         2\n",
            "  21BEIT30053       0.50      1.00      0.67         2\n",
            "  21BEIT30090       0.50      0.33      0.40         3\n",
            "  21BEIT30092       0.29      1.00      0.44         2\n",
            "  21BEIT30100       0.25      0.50      0.33         2\n",
            "  21BEIT30105       0.80      1.00      0.89         4\n",
            "  21BEIT30128       1.00      0.25      0.40         4\n",
            "  21BEIT30135       0.00      0.00      0.00         2\n",
            "222SBEIT30014       0.00      0.00      0.00         3\n",
            "\n",
            "     accuracy                           0.52        33\n",
            "    macro avg       0.50      0.53      0.43        33\n",
            " weighted avg       0.60      0.52      0.46        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "YgU_x7OSHaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d45302f-9523-43a8-c560-a986733eaba7",
        "id": "z7tqWb6BHaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3333\n",
            "F1 Score: 0.2329\n",
            "Precision: 0.2305\n",
            "Recall: 0.3333\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         5\n",
            "  21BEIT30044       1.00      0.50      0.67         4\n",
            "  21BEIT30048       0.33      0.50      0.40         2\n",
            "  21BEIT30053       0.40      1.00      0.57         2\n",
            "  21BEIT30090       0.00      0.00      0.00         3\n",
            "  21BEIT30092       0.18      1.00      0.31         2\n",
            "  21BEIT30100       0.00      0.00      0.00         2\n",
            "  21BEIT30105       0.44      1.00      0.62         4\n",
            "  21BEIT30128       0.00      0.00      0.00         4\n",
            "  21BEIT30135       0.00      0.00      0.00         2\n",
            "222SBEIT30014       0.00      0.00      0.00         3\n",
            "\n",
            "     accuracy                           0.33        33\n",
            "    macro avg       0.21      0.36      0.23        33\n",
            " weighted avg       0.23      0.33      0.23        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "Zllpa0_BHaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313ad204-77a0-4276-f384-6e935901d859",
        "id": "luGry6gmHaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5152\n",
            "F1 Score: 0.4582\n",
            "Precision: 0.6229\n",
            "Recall: 0.5152\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.20      0.33         5\n",
            "  21BEIT30044       0.80      1.00      0.89         4\n",
            "  21BEIT30048       0.50      0.50      0.50         2\n",
            "  21BEIT30053       0.50      1.00      0.67         2\n",
            "  21BEIT30090       1.00      0.33      0.50         3\n",
            "  21BEIT30092       0.29      1.00      0.44         2\n",
            "  21BEIT30100       0.25      0.50      0.33         2\n",
            "  21BEIT30105       0.57      1.00      0.73         4\n",
            "  21BEIT30128       1.00      0.25      0.40         4\n",
            "  21BEIT30135       0.00      0.00      0.00         2\n",
            "222SBEIT30014       0.00      0.00      0.00         3\n",
            "\n",
            "     accuracy                           0.52        33\n",
            "    macro avg       0.54      0.53      0.44        33\n",
            " weighted avg       0.62      0.52      0.46        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-knn'></a>\n",
        "### R=3 - KSV dataset : KNN"
      ],
      "metadata": {
        "id": "y30gdBp8HaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a189af78-f3f5-4c0e-be3c-b6ca70d23895",
        "id": "-Z0W_JtXHaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2727\n",
            "F1 Score: 0.1804\n",
            "Precision: 0.1485\n",
            "Recall: 0.2727\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.00      0.00      0.00         3\n",
            "  21BEIT30044       0.67      1.00      0.80         2\n",
            "  21BEIT30048       0.27      1.00      0.43         3\n",
            "  21BEIT30053       0.00      0.00      0.00         3\n",
            "  21BEIT30090       0.00      0.00      0.00         3\n",
            "  21BEIT30092       0.25      0.50      0.33         2\n",
            "  21BEIT30100       0.00      0.00      0.00         3\n",
            "  21BEIT30105       0.12      0.50      0.20         2\n",
            "  21BEIT30128       0.00      0.00      0.00         6\n",
            "  21BEIT30135       0.50      0.50      0.50         4\n",
            "222SBEIT30014       0.00      0.00      0.00         2\n",
            "\n",
            "     accuracy                           0.27        33\n",
            "    macro avg       0.16      0.32      0.21        33\n",
            " weighted avg       0.15      0.27      0.18        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "6fEX3NEQHaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd143b0f-80e3-459b-910f-f911c363ab92",
        "id": "TqM0F3U8HaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4242\n",
            "F1 Score: 0.4209\n",
            "Precision: 0.4889\n",
            "Recall: 0.4242\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 1 0 0 0 1 0 0 0 0]\n",
            " [0 5 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 0 0 0 3 1]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 1 0 1 1]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       1.00      0.33      0.50         3\n",
            "  21BEIT30044       0.83      0.83      0.83         6\n",
            "  21BEIT30048       0.50      0.75      0.60         4\n",
            "  21BEIT30053       1.00      0.33      0.50         3\n",
            "  21BEIT30090       0.67      1.00      0.80         2\n",
            "  21BEIT30092       0.00      0.00      0.00         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.50      0.50      0.50         2\n",
            "  21BEIT30128       0.00      0.00      0.00         1\n",
            "  21BEIT30135       0.20      0.25      0.22         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.42        33\n",
            "    macro avg       0.43      0.36      0.36        33\n",
            " weighted avg       0.49      0.42      0.42        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-ksv-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "8wCGz5r6HaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3c5ff1-2f26-43c6-f5f7-5f6e7561af1e",
        "id": "x72mLMV3HaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4242\n",
            "F1 Score: 0.3667\n",
            "Precision: 0.3838\n",
            "Recall: 0.4242\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 1 0 1 0 0 0 0 0 0]\n",
            " [0 5 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 2 0 3 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 2 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "209SBEIT30133       0.50      0.33      0.40         3\n",
            "  21BEIT30044       0.56      0.83      0.67         6\n",
            "  21BEIT30048       0.75      0.75      0.75         4\n",
            "  21BEIT30053       1.00      0.33      0.50         3\n",
            "  21BEIT30090       0.67      1.00      0.80         2\n",
            "  21BEIT30092       0.00      0.00      0.00         6\n",
            "  21BEIT30100       0.00      0.00      0.00         1\n",
            "  21BEIT30105       0.25      1.00      0.40         2\n",
            "  21BEIT30128       0.00      0.00      0.00         1\n",
            "  21BEIT30135       0.00      0.00      0.00         4\n",
            "222SBEIT30014       0.00      0.00      0.00         1\n",
            "\n",
            "     accuracy                           0.42        33\n",
            "    macro avg       0.34      0.39      0.32        33\n",
            " weighted avg       0.38      0.42      0.37        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset'></a>\n",
        "## LBP (R=3) on Yale Dataset"
      ],
      "metadata": {
        "id": "YKdaLM07HaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for gif_file in os.listdir(class_path):\n",
        "            gif_path = os.path.join(class_path, gif_file)\n",
        "\n",
        "            gif_image = Image.open(gif_path)\n",
        "            rgb_image = gif_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features_3(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/Yale_Dataset/Train\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "vX-KmuLgHaD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-svc'></a>\n",
        "### R=3 - Yale dataset : SVC"
      ],
      "metadata": {
        "id": "fBtg2CSZHaD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "lWWNQ344HaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec57b37-1884-4991-d828-2996899f73f6",
        "id": "32NRHJ83HaD8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7576\n",
            "F1 Score: 0.7719\n",
            "Precision: 0.9141\n",
            "Recall: 0.7576\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.50      1.00      0.67         1\n",
            "   subject04       0.83      1.00      0.91         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       1.00      1.00      1.00         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       0.50      1.00      0.67         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.33      0.50         3\n",
            "   subject15       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.82      0.77      0.74        33\n",
            "weighted avg       0.91      0.76      0.77        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "NIKoisZYHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe177043-ed15-42f3-87ea-a79c1d23b60f",
        "id": "xlXLuKc7HaD9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6364\n",
            "F1 Score: 0.6694\n",
            "Precision: 0.8927\n",
            "Recall: 0.6364\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.33      0.50         3\n",
            "   subject03       1.00      1.00      1.00         1\n",
            "   subject04       1.00      1.00      1.00         5\n",
            "   subject05       1.00      0.50      0.67         2\n",
            "   subject06       0.12      1.00      0.22         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       0.50      1.00      0.67         2\n",
            "   subject13       1.00      0.50      0.67         4\n",
            "   subject14       1.00      0.33      0.50         3\n",
            "   subject15       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.64        33\n",
            "   macro avg       0.75      0.63      0.61        33\n",
            "weighted avg       0.89      0.64      0.67        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "4pdGfE4mHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ebc3f7-641f-4936-e9c7-2f0973964c2a",
        "id": "EuRoPgo3HaD9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7879\n",
            "F1 Score: 0.7985\n",
            "Precision: 0.9182\n",
            "Recall: 0.7879\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       1.00      0.67      0.80         3\n",
            "   subject03       0.33      1.00      0.50         1\n",
            "   subject04       0.83      1.00      0.91         5\n",
            "   subject05       1.00      1.00      1.00         2\n",
            "   subject06       1.00      1.00      1.00         1\n",
            "   subject07       0.00      0.00      0.00         0\n",
            "   subject08       1.00      0.25      0.40         4\n",
            "   subject09       1.00      1.00      1.00         1\n",
            "   subject10       1.00      1.00      1.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      0.75      0.86         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.79        33\n",
            "   macro avg       0.84      0.79      0.77        33\n",
            "weighted avg       0.92      0.79      0.80        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-knn'></a>\n",
        "### R=3 - Yale dataset : KNN"
      ],
      "metadata": {
        "id": "9X0ckiFfHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429744e1-1d9e-490d-9af9-2a1231e5210c",
        "id": "QMrD7NpZHaD9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7576\n",
            "F1 Score: 0.7655\n",
            "Precision: 0.8551\n",
            "Recall: 0.7576\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   subject01       1.00      0.50      0.67         2\n",
            "   subject02       0.00      0.00      0.00         1\n",
            "   subject03       1.00      0.50      0.67         2\n",
            "   subject04       1.00      0.50      0.67         4\n",
            "   subject05       0.60      1.00      0.75         3\n",
            "   subject06       0.00      0.00      0.00         0\n",
            "   subject07       0.83      1.00      0.91         5\n",
            "   subject08       1.00      1.00      1.00         1\n",
            "   subject09       0.50      0.50      0.50         2\n",
            "   subject10       0.25      1.00      0.40         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      0.50      0.67         2\n",
            "   subject13       1.00      1.00      1.00         4\n",
            "   subject14       1.00      0.67      0.80         3\n",
            "   subject15       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.76        33\n",
            "   macro avg       0.75      0.68      0.67        33\n",
            "weighted avg       0.86      0.76      0.77        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "CL93o3VUHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffe3418-d105-484c-c5ae-0b0ffaf17ef2",
        "id": "sinEMf4jHaD9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8182\n",
            "F1 Score: 0.8261\n",
            "Precision: 0.8990\n",
            "Recall: 0.8182\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 2]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       1.00      1.00      1.00         5\n",
            "   subject03       1.00      0.50      0.67         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       1.00      0.75      0.86         4\n",
            "   subject07       0.33      1.00      0.50         1\n",
            "   subject08       0.50      1.00      0.67         2\n",
            "   subject09       1.00      0.50      0.67         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       1.00      1.00      1.00         2\n",
            "   subject14       0.67      1.00      0.80         2\n",
            "   subject15       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.82        33\n",
            "   macro avg       0.75      0.74      0.71        33\n",
            "weighted avg       0.90      0.82      0.83        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-yale-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "6vK9U7a9HaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19d0d29-3250-4b13-9d93-9535a3a8beb5",
        "id": "e2amTF5oHaD9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6667\n",
            "F1 Score: 0.5899\n",
            "Precision: 0.5804\n",
            "Recall: 0.6667\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 1 0 1 0 0 0 0 0 0 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   subject02       0.71      1.00      0.83         5\n",
            "   subject03       0.00      0.00      0.00         4\n",
            "   subject04       0.00      0.00      0.00         0\n",
            "   subject05       1.00      1.00      1.00         3\n",
            "   subject06       0.67      1.00      0.80         4\n",
            "   subject07       0.25      1.00      0.40         1\n",
            "   subject08       0.00      0.00      0.00         2\n",
            "   subject09       0.00      0.00      0.00         2\n",
            "   subject10       0.00      0.00      0.00         1\n",
            "   subject11       1.00      1.00      1.00         2\n",
            "   subject12       1.00      1.00      1.00         2\n",
            "   subject13       0.67      1.00      0.80         2\n",
            "   subject14       0.67      1.00      0.80         2\n",
            "   subject15       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.67        33\n",
            "   macro avg       0.50      0.60      0.51        33\n",
            "weighted avg       0.58      0.67      0.59        33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset'></a>\n",
        "## LBP (R=3) on ORL Dataset"
      ],
      "metadata": {
        "id": "ZO7Hn7QuHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features_3(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/ORL_Dataset\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "TGsFDnupHaD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-svc'></a>\n",
        "### R=3 - ORL dataset : SVC"
      ],
      "metadata": {
        "id": "j1ny9v8RHaD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "LkDEaUbRHaD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fc89c0-f89b-45c2-c314-a5e38a0f332f",
        "id": "C4fq61BpHaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9625\n",
            "F1 Score: 0.9651\n",
            "Precision: 0.9833\n",
            "Recall: 0.9625\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      1.00      1.00         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      0.50      0.67         4\n",
            "         s15       1.00      1.00      1.00         2\n",
            "         s16       1.00      1.00      1.00         1\n",
            "         s17       1.00      1.00      1.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         2\n",
            "         s20       1.00      0.80      0.89         5\n",
            "         s21       1.00      1.00      1.00         3\n",
            "         s22       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       1.00      1.00      1.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.33      1.00      0.50         1\n",
            "         s29       1.00      1.00      1.00         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      1.00      1.00         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       0.67      1.00      0.80         2\n",
            "         s39       1.00      1.00      1.00         1\n",
            "         s40       1.00      1.00      1.00         3\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.98      0.97        80\n",
            "weighted avg       0.98      0.96      0.97        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "qXTdgqoOHaD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d21255-140a-4eb5-a8b6-b9553ca77d73",
        "id": "rcYXJvYaHaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5875\n",
            "F1 Score: 0.6053\n",
            "Precision: 0.7087\n",
            "Recall: 0.5875\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       0.00      0.00      0.00         3\n",
            "         s10       1.00      1.00      1.00         1\n",
            "         s11       1.00      0.25      0.40         4\n",
            "         s12       1.00      1.00      1.00         3\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       0.00      0.00      0.00         4\n",
            "         s15       1.00      0.50      0.67         2\n",
            "         s16       0.07      1.00      0.13         1\n",
            "         s17       0.00      0.00      0.00         4\n",
            "         s18       1.00      1.00      1.00         1\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      0.50      0.67         2\n",
            "         s20       0.00      0.00      0.00         5\n",
            "         s21       1.00      0.33      0.50         3\n",
            "         s22       0.00      0.00      0.00         1\n",
            "         s23       1.00      1.00      1.00         3\n",
            "         s24       0.00      0.00      0.00         4\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s26       0.00      0.00      0.00         0\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.50      1.00      0.67         1\n",
            "         s29       1.00      0.50      0.67         2\n",
            "          s3       1.00      1.00      1.00         2\n",
            "         s30       1.00      0.67      0.80         3\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         2\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      1.00      1.00         1\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         1\n",
            "         s38       1.00      1.00      1.00         2\n",
            "         s39       0.12      1.00      0.22         1\n",
            "          s4       0.00      0.00      0.00         0\n",
            "         s40       1.00      0.33      0.50         3\n",
            "          s5       1.00      0.67      0.80         3\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         1\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.59        80\n",
            "   macro avg       0.74      0.69      0.68        80\n",
            "weighted avg       0.71      0.59      0.61        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "A9APTzdEHaD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaec8160-26bd-4c93-d757-1c469312e52f",
        "id": "CSiUv2gOHaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9250\n",
            "F1 Score: 0.9185\n",
            "Precision: 0.9677\n",
            "Recall: 0.9250\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         3\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         1\n",
            "         s13       1.00      1.00      1.00         1\n",
            "         s14       1.00      1.00      1.00         3\n",
            "         s15       1.00      1.00      1.00         4\n",
            "         s16       1.00      1.00      1.00         3\n",
            "         s17       1.00      1.00      1.00         2\n",
            "         s18       1.00      1.00      1.00         2\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       0.33      1.00      0.50         1\n",
            "         s23       1.00      1.00      1.00         2\n",
            "         s24       1.00      1.00      1.00         1\n",
            "         s25       1.00      1.00      1.00         1\n",
            "         s26       1.00      0.75      0.86         4\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.75      1.00      0.86         3\n",
            "         s29       0.50      1.00      0.67         1\n",
            "          s3       0.00      0.00      0.00         0\n",
            "         s30       1.00      1.00      1.00         1\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         1\n",
            "         s33       1.00      0.17      0.29         6\n",
            "         s34       1.00      1.00      1.00         3\n",
            "         s35       0.67      1.00      0.80         2\n",
            "         s36       1.00      1.00      1.00         1\n",
            "         s37       1.00      1.00      1.00         2\n",
            "         s38       1.00      1.00      1.00         4\n",
            "         s39       1.00      1.00      1.00         4\n",
            "          s4       1.00      1.00      1.00         2\n",
            "         s40       1.00      1.00      1.00         2\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         1\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         2\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.93        80\n",
            "   macro avg       0.93      0.94      0.92        80\n",
            "weighted avg       0.97      0.93      0.92        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-knn'></a>\n",
        "### R=3 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "4wx0O6FOHaD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0655f56-07f8-44e3-f090-79ea92989d8e",
        "id": "KqD87UL2HaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8250\n",
            "F1 Score: 0.8192\n",
            "Precision: 0.8854\n",
            "Recall: 0.8250\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      0.33      0.50         3\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         1\n",
            "         s13       0.33      1.00      0.50         1\n",
            "         s14       0.50      1.00      0.67         3\n",
            "         s15       0.67      1.00      0.80         4\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s17       1.00      1.00      1.00         2\n",
            "         s18       0.67      1.00      0.80         2\n",
            "         s19       1.00      1.00      1.00         2\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         1\n",
            "         s23       1.00      1.00      1.00         2\n",
            "         s24       1.00      1.00      1.00         1\n",
            "         s25       0.00      0.00      0.00         1\n",
            "         s26       1.00      0.50      0.67         4\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      0.67      0.80         3\n",
            "         s29       1.00      1.00      1.00         1\n",
            "         s30       0.33      1.00      0.50         1\n",
            "         s31       1.00      1.00      1.00         1\n",
            "         s32       1.00      1.00      1.00         1\n",
            "         s33       1.00      0.50      0.67         6\n",
            "         s34       1.00      1.00      1.00         3\n",
            "         s35       1.00      0.50      0.67         2\n",
            "         s36       0.00      0.00      0.00         1\n",
            "         s37       0.67      1.00      0.80         2\n",
            "         s38       1.00      1.00      1.00         4\n",
            "         s39       0.75      0.75      0.75         4\n",
            "          s4       1.00      1.00      1.00         2\n",
            "         s40       1.00      0.50      0.67         2\n",
            "          s5       1.00      1.00      1.00         3\n",
            "          s6       1.00      1.00      1.00         1\n",
            "          s7       0.33      1.00      0.50         1\n",
            "          s8       1.00      1.00      1.00         2\n",
            "          s9       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.84      0.84      0.81        80\n",
            "weighted avg       0.89      0.82      0.82        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "ituW7lNlHaD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fc25b4-c914-43f3-b43d-d9cf051a3374",
        "id": "mIyB1TDXHaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8500\n",
            "F1 Score: 0.8555\n",
            "Precision: 0.9177\n",
            "Recall: 0.8500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         1\n",
            "         s10       0.50      1.00      0.67         2\n",
            "         s11       1.00      1.00      1.00         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       0.67      1.00      0.80         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       1.00      1.00      1.00         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       1.00      0.67      0.80         3\n",
            "         s19       0.00      0.00      0.00         0\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       1.00      1.00      1.00         4\n",
            "         s23       1.00      0.33      0.50         3\n",
            "         s24       1.00      0.50      0.67         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       1.00      1.00      1.00         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       1.00      0.67      0.80         3\n",
            "         s32       1.00      0.50      0.67         4\n",
            "         s33       0.33      1.00      0.50         1\n",
            "         s34       1.00      1.00      1.00         2\n",
            "         s35       1.00      0.50      0.67         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.75      1.00      0.86         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       0.67      1.00      0.80         2\n",
            "         s40       0.33      0.50      0.40         2\n",
            "          s5       0.50      0.50      0.50         2\n",
            "          s6       1.00      1.00      1.00         2\n",
            "          s7       1.00      1.00      1.00         1\n",
            "          s8       1.00      1.00      1.00         3\n",
            "          s9       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.85        80\n",
            "   macro avg       0.87      0.85      0.83        80\n",
            "weighted avg       0.92      0.85      0.86        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-orl-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "oifV6jSRHaD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02a0e62-9a45-4770-b55b-c449eddc0329",
        "id": "QeTg_w4vHaD-"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8375\n",
            "F1 Score: 0.8158\n",
            "Precision: 0.8275\n",
            "Recall: 0.8375\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 3 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          s1       1.00      1.00      1.00         1\n",
            "         s10       1.00      1.00      1.00         2\n",
            "         s11       1.00      1.00      1.00         3\n",
            "         s12       1.00      1.00      1.00         2\n",
            "         s13       1.00      1.00      1.00         2\n",
            "         s14       1.00      1.00      1.00         2\n",
            "         s15       1.00      1.00      1.00         1\n",
            "         s16       1.00      0.67      0.80         3\n",
            "         s18       1.00      0.67      0.80         3\n",
            "          s2       1.00      1.00      1.00         3\n",
            "         s20       1.00      1.00      1.00         2\n",
            "         s21       0.80      1.00      0.89         4\n",
            "         s23       1.00      0.67      0.80         3\n",
            "         s24       1.00      1.00      1.00         2\n",
            "         s25       1.00      1.00      1.00         2\n",
            "         s26       1.00      1.00      1.00         1\n",
            "         s27       1.00      1.00      1.00         3\n",
            "         s28       0.67      1.00      0.80         2\n",
            "         s29       1.00      1.00      1.00         3\n",
            "          s3       1.00      1.00      1.00         1\n",
            "         s30       1.00      1.00      1.00         4\n",
            "         s31       0.00      0.00      0.00         3\n",
            "         s32       0.75      0.75      0.75         4\n",
            "         s33       1.00      1.00      1.00         1\n",
            "         s34       0.50      1.00      0.67         2\n",
            "         s35       0.50      0.50      0.50         2\n",
            "         s36       1.00      0.50      0.67         2\n",
            "         s38       0.75      1.00      0.86         3\n",
            "         s39       1.00      1.00      1.00         1\n",
            "          s4       1.00      0.50      0.67         2\n",
            "         s40       0.00      0.00      0.00         2\n",
            "          s5       0.50      0.50      0.50         2\n",
            "          s6       0.67      1.00      0.80         2\n",
            "          s7       0.50      1.00      0.67         1\n",
            "          s8       0.75      1.00      0.86         3\n",
            "          s9       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.83      0.85      0.82        80\n",
            "weighted avg       0.83      0.84      0.82        80\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MuUiL4bHJC7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset'></a>\n",
        "## LBP (R=3) on LFW Dataset"
      ],
      "metadata": {
        "id": "VrfIzBfwJDTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loading\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "    target_size = (240,240)\n",
        "\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        for pgm_file in os.listdir(class_path):\n",
        "            pgm_path = os.path.join(class_path, pgm_file)\n",
        "\n",
        "            pgm_image = Image.open(pgm_path)\n",
        "            rgb_image = pgm_image.convert(\"RGB\")\n",
        "            resized_image = rgb_image.resize(target_size)\n",
        "\n",
        "            image = cv2.cvtColor(np.array(resized_image), cv2.COLOR_RGB2BGR)\n",
        "            lbp_features = get_lbp_features(image)\n",
        "            data.append(lbp_features)\n",
        "            labels.append(class_folder)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "dataset_path = \"/content/drive/Shareddrives/Coding Brigades/Dataset/Face_Recognition_Dataset/lfw100\"\n",
        "data, labels = load_dataset(dataset_path)\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=52)"
      ],
      "metadata": {
        "id": "ZeBZEBe3JDTq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-svc'></a>\n",
        "### R=3 - LFW dataset : SVC"
      ],
      "metadata": {
        "id": "rNWRljj-JDTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-svc-linear-kernel'></a>\n",
        "#### SVC : Linear Kernel"
      ],
      "metadata": {
        "id": "tBITSTCEJDTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702a13e6-cf4f-4655-8ea0-807aac54606f",
        "id": "GAIkeXRVJDTr"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0467\n",
            "Precision: 0.0581\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.09      1.00      0.16         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-svc-rbf-kernel'></a>\n",
        "#### SVC : RBF Kernel"
      ],
      "metadata": {
        "id": "ofrAs6oJJDTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='rbf', C=2.0, random_state=72)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa3628c-1879-42bb-a92a-36b86cfb0fa8",
        "id": "aWl3yGt7JDTs"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0110\n",
            "Precision: 0.0059\n",
            "Recall: 0.0769\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.08      1.00      0.14         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       0.00      0.00      0.00         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.08        39\n",
            "           macro avg       0.00      0.03      0.00        39\n",
            "        weighted avg       0.01      0.08      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-svc-sigmoid'></a>\n",
        "#### SVC : Sigmoid"
      ],
      "metadata": {
        "id": "IQHlUUGsJDTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the SVC classifier\n",
        "svc_classifier = SVC(kernel='sigmoid', C=3.0, random_state=42)\n",
        "svc_classifier.fit(X_train_std, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = svc_classifier.predict(X_test_std)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Predict decision function scores on the test set\n",
        "decision_scores = svc_classifier.decision_function(X_test_std)\n",
        "\n",
        "# Calculate top-2 accuracy based on decision function scores\n",
        "top2_accuracy = 0\n",
        "for true_label, scores in zip(y_test, decision_scores):\n",
        "    top2_indices = np.argsort(scores)[-2:]  # Indices of top 2 predicted classes\n",
        "    if true_label == top2_indices[0] or true_label == top2_indices[1]:\n",
        "        top2_accuracy += 1\n",
        "\n",
        "top2_accuracy /= len(y_test)\n",
        "\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'Top-2 Accuracy: {top2_accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1206d8ed-825e-437d-f516-4bddbd20f15b",
        "id": "MjOaRmp5JDTs"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1026\n",
            "F1 Score: 0.0478\n",
            "Precision: 0.0587\n",
            "Recall: 0.1026\n",
            "Top-2 Accuracy: 0.0000\n",
            "Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "       Aaron_Eckhart       0.00      0.00      0.00         1\n",
            "       Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "        Aaron_Sorkin       0.00      0.00      0.00         1\n",
            "  Abdel_Madi_Shabneh       0.00      0.00      0.00         1\n",
            " Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "        Abdullah_Gul       0.10      1.00      0.18         3\n",
            " Abdullah_al-Attiyah       0.00      0.00      0.00         2\n",
            "        Abel_Pacheco       0.00      0.00      0.00         2\n",
            "            Adam_Ant       0.00      0.00      0.00         1\n",
            "        Adam_Kennedy       0.00      0.00      0.00         1\n",
            "    Adrian_Fernandez       0.00      0.00      0.00         1\n",
            "    Adrian_McPherson       0.00      0.00      0.00         1\n",
            "      Adrian_Murrell       0.00      0.00      0.00         1\n",
            "        Adriana_Lima       0.00      0.00      0.00         1\n",
            "      Adrianna_Zuzic       0.00      0.00      0.00         1\n",
            "        Adrien_Brody       0.00      0.00      0.00         1\n",
            "         Ahmed_Ghazi       0.00      0.00      0.00         1\n",
            " Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         1\n",
            "         Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "        Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "         Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "        Aiysha_Smith       0.00      0.00      0.00         1\n",
            "      Akbar_Al_Baker       0.00      0.00      0.00         1\n",
            "      Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "             Al_Gore       1.00      0.50      0.67         2\n",
            "           Al_Pacino       0.00      0.00      0.00         1\n",
            "         Al_Sharpton       0.00      0.00      0.00         2\n",
            "           Alan_Ball       0.00      0.00      0.00         2\n",
            "      Alan_Greenspan       0.00      0.00      0.00         2\n",
            "        Alan_Mulally       0.00      0.00      0.00         1\n",
            "Alan_Tang_Kwong-wing       0.00      0.00      0.00         1\n",
            "\n",
            "            accuracy                           0.10        39\n",
            "           macro avg       0.04      0.05      0.03        39\n",
            "        weighted avg       0.06      0.10      0.05        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-knn'></a>\n",
        "### R=3 - ORL dataset : KNN"
      ],
      "metadata": {
        "id": "6vk6QQuWJDTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "k = 3  # Number of neighbors (you can adjust this)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k,p=3,algorithm='ball_tree',weights='distance')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('Classification Report:\\n', classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a97900-c484-48f9-9e56-fe66b61bca8b",
        "id": "MiHPel6IJDTt"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0256\n",
            "F1 Score: 0.0114\n",
            "Precision: 0.0073\n",
            "Recall: 0.0256\n",
            "Classification Report:\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "                     AJ_Cook       0.00      0.00      0.00         1\n",
            "                 Aaron_Guiel       0.00      0.00      0.00         1\n",
            "             Aaron_Patterson       0.00      0.00      0.00         1\n",
            "                  Aaron_Pena       0.00      0.00      0.00         0\n",
            "                Aaron_Tippin       0.00      0.00      0.00         1\n",
            "         Abdel_Aziz_Al-Hakim       0.00      0.00      0.00         0\n",
            "          Abdel_Madi_Shabneh       0.00      0.00      0.00         0\n",
            "         Abdel_Nasser_Assidi       0.00      0.00      0.00         1\n",
            "      Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "                    Abdullah       0.00      0.00      0.00         1\n",
            "                Abdullah_Gul       0.14      0.50      0.22         2\n",
            "            Abdullah_Nasseef       0.00      0.00      0.00         1\n",
            "            Abdullatif_Sener       0.00      0.00      0.00         1\n",
            "                Abel_Aguilar       0.00      0.00      0.00         1\n",
            "                Abel_Pacheco       0.00      0.00      0.00         1\n",
            "Abid_Hamid_Mahmud_Al-Tikriti       0.00      0.00      0.00         0\n",
            "                    Adam_Ant       0.00      0.00      0.00         0\n",
            "                Adam_Sandler       0.00      0.00      0.00         2\n",
            "                  Adam_Scott       0.00      0.00      0.00         1\n",
            "               Adelina_Avila       0.00      0.00      0.00         1\n",
            "       Adolfo_Aguilar_Zinser       0.00      0.00      0.00         1\n",
            "        Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "            Adrian_McPherson       0.00      0.00      0.00         0\n",
            "              Adrian_Nastase       0.00      0.00      0.00         0\n",
            "       Adriana_Perez_Navarro       0.00      0.00      0.00         0\n",
            "              Adrianna_Zuzic       0.00      0.00      0.00         0\n",
            "                Adrien_Brody       0.00      0.00      0.00         4\n",
            "              Agnelo_Queiroz       0.00      0.00      0.00         1\n",
            "                Ahmad_Masood       0.00      0.00      0.00         2\n",
            "                 Ahmed_Ahmed       0.00      0.00      0.00         1\n",
            "               Ahmed_Chalabi       0.00      0.00      0.00         2\n",
            "         Ahmed_Ibrahim_Bilal       0.00      0.00      0.00         0\n",
            "                 Ahmed_Lopez       0.00      0.00      0.00         1\n",
            "                Ahmed_Qureia       0.00      0.00      0.00         1\n",
            "          Ahmet_Necdet_Sezer       0.00      0.00      0.00         1\n",
            "              Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "                 Aidan_Quinn       0.00      0.00      0.00         0\n",
            "              Ainsworth_Dyer       0.00      0.00      0.00         1\n",
            "    Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         0\n",
            "              Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "              Akiko_Morigami       0.00      0.00      0.00         0\n",
            "                    Al_Davis       0.00      0.00      0.00         1\n",
            "                     Al_Gore       0.00      0.00      0.00         0\n",
            "                 Al_Sharpton       0.00      0.00      0.00         1\n",
            "              Alan_Greenspan       0.00      0.00      0.00         1\n",
            "            Alan_Stonecipher       0.00      0.00      0.00         0\n",
            "               Alan_Trammell       0.00      0.00      0.00         1\n",
            "\n",
            "                    accuracy                           0.03        39\n",
            "                   macro avg       0.00      0.01      0.00        39\n",
            "                weighted avg       0.01      0.03      0.01        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-knn-penalty-none'></a>\n",
        "#### KNN : Penalty = \"none\""
      ],
      "metadata": {
        "id": "KIC44dWBJDTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='none',class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd97186-2742-4e95-ab36-4b91a6c37646",
        "id": "Nx6MP-wAJDTt"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1538\n",
            "F1 Score: 0.1251\n",
            "Precision: 0.1103\n",
            "Recall: 0.1538\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.29      0.40      0.33         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "                Adam_Ant       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "              Adam_Scott       0.00      0.00      0.00         0\n",
            "          Adel_Al-Jubeir       0.50      1.00      0.67         1\n",
            "    Adolfo_Rodriguez_Saa       0.00      0.00      0.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.12      0.33      0.18         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "      Ahmet_Necdet_Sezer       0.00      0.00      0.00         0\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       1.00      1.00      1.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.00      0.00      0.00         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "                 Al_Gore       0.25      0.25      0.25         4\n",
            "             Al_Sharpton       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.15        39\n",
            "               macro avg       0.07      0.09      0.07        39\n",
            "            weighted avg       0.11      0.15      0.13        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='lbp-r-3-lfw-dataset-knn-penalty-l2'></a>\n",
        "#### KNN : Penalty = \"l2\""
      ],
      "metadata": {
        "id": "w6PNy08SJDTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (e.g., 80% training and 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=101)\n",
        "\n",
        "model = LogisticRegression(penalty='l2',class_weight='balanced',max_iter=400)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print('\\nConfusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a7f3d3-1999-431f-8e4a-840149e281ae",
        "id": "nj1GdlhbJDTt"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0769\n",
            "F1 Score: 0.0403\n",
            "Precision: 0.0342\n",
            "Recall: 0.0769\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                 AJ_Cook       0.00      0.00      0.00         1\n",
            "           Aaron_Eckhart       0.00      0.00      0.00         0\n",
            "             Aaron_Guiel       0.00      0.00      0.00         1\n",
            "           Aaron_Peirsol       0.00      0.00      0.00         1\n",
            "  Abdul_Majeed_Shobokshi       0.00      0.00      0.00         1\n",
            "            Abdul_Rahman       0.00      0.00      0.00         0\n",
            "       Abdulaziz_Kamilov       0.00      0.00      0.00         1\n",
            "                Abdullah       0.00      0.00      0.00         1\n",
            "            Abdullah_Gul       0.00      0.00      0.00         5\n",
            "            Abel_Pacheco       0.00      0.00      0.00         1\n",
            "          Abner_Martinez       0.00      0.00      0.00         1\n",
            "               Adam_Mair       0.00      0.00      0.00         0\n",
            "               Adam_Rich       0.00      0.00      0.00         1\n",
            "            Adam_Sandler       0.00      0.00      0.00         1\n",
            "          Adel_Al-Jubeir       0.00      0.00      0.00         1\n",
            "    Adolfo_Rodriguez_Saa       1.00      1.00      1.00         1\n",
            "        Adrian_McPherson       0.00      0.00      0.00         1\n",
            "            Adriana_Lima       0.00      0.00      0.00         0\n",
            "   Adriana_Perez_Navarro       0.00      0.00      0.00         1\n",
            "            Adrien_Brody       0.00      0.00      0.00         3\n",
            "          Agnes_Bruckner       0.00      0.00      0.00         1\n",
            "            Ahmad_Jbarah       0.00      0.00      0.00         0\n",
            "            Ahmad_Masood       0.00      0.00      0.00         1\n",
            "           Ahmed_Chalabi       0.00      0.00      0.00         3\n",
            "             Ahmet_Demir       0.00      0.00      0.00         1\n",
            "             Ai_Sugiyama       0.00      0.00      0.00         1\n",
            "          Aicha_El_Ouafi       0.00      0.00      0.00         1\n",
            "              Ain_Seppik       0.00      0.00      0.00         0\n",
            "            Aiysha_Smith       0.00      0.00      0.00         0\n",
            "          Akbar_Al_Baker       0.00      0.00      0.00         0\n",
            "Akbar_Hashemi_Rafsanjani       0.17      1.00      0.29         2\n",
            "          Akhmed_Zakayev       0.00      0.00      0.00         1\n",
            "          Akiko_Morigami       0.00      0.00      0.00         0\n",
            "             Akmal_Taher       0.00      0.00      0.00         0\n",
            "             Al_Cardenas       0.00      0.00      0.00         0\n",
            "                 Al_Gore       0.00      0.00      0.00         4\n",
            "               Al_Leiter       0.00      0.00      0.00         0\n",
            "         Alain_Cervantes       0.00      0.00      0.00         1\n",
            "           Alain_Ducasse       0.00      0.00      0.00         0\n",
            "          Alan_Greenspan       0.00      0.00      0.00         1\n",
            "\n",
            "                accuracy                           0.08        39\n",
            "               macro avg       0.03      0.05      0.03        39\n",
            "            weighted avg       0.03      0.08      0.04        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Jjysa0IJDTu"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}